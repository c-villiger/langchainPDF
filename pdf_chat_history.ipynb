{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tabulate numpy pandas langchain openai chromadb pypdf tiktoken faiss-cpu Flask unstructured Cython pdfminer.six termcolor tabulate tqdm reportlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cesar\\OneDrive\\Desktop\\Code\\langchain-pdf-bot\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Document loaders\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "# Splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "# Embeddings and models\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import FAISS, Chroma\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "# Chains\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "# Utils\n",
    "import os\n",
    "from termcolor import colored\n",
    "import textwrap\n",
    "from prettytable import PrettyTable\n",
    "import ast\n",
    "from tqdm.auto import tqdm\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import docx\n",
    "from reportlab.lib.pagesizes import letter, landscape\n",
    "from reportlab.lib import colors\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, PageBreak\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Import API Key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folder Path Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r\"C:\\Users\\cesar\\OneDrive\\Desktop\\test2\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ```qa_single_file```\n",
    "This iterates over each file seperately, asking each one the same question. Good for literature overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_single_file(folder_path, chain_type, chunk_size, query, k, own_knowledge = False, show_pages=False):\n",
    "\n",
    "    # Define output table.\n",
    "    tables = {}\n",
    "\n",
    "    # Wraptext function for prettytable\n",
    "    def wrap_text(text, width=40):\n",
    "        return \"\\n\".join(textwrap.wrap(text, width=width))\n",
    "\n",
    "    \"\"\"\n",
    "    Read-in and split the documents\n",
    "    \"\"\"\n",
    "    # Loop over all files in folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        # Clear all_pages\n",
    "        all_pages = []\n",
    "\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        if file_name.endswith('.pdf'):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif file_name.endswith('.csv'):\n",
    "            loader = CSVLoader(file_path)\n",
    "        elif file_name.endswith('.docx'):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        elif file_name.endswith('.md'):\n",
    "            loader = UnstructuredMarkdownLoader(file_path)\n",
    "        else:\n",
    "            continue  # Skip files with other extensions\n",
    "\n",
    "        file = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_size/2)\n",
    "        pages = text_splitter.split_documents(file)\n",
    "        all_pages.extend(pages)\n",
    "\n",
    "        if show_pages:\n",
    "            print(len(all_pages))\n",
    "            for page in all_pages:\n",
    "                print(page)\n",
    "\n",
    "        \"\"\"\n",
    "        Vectorstores\n",
    "        \"\"\"\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "\n",
    "        db = FAISS.from_documents(all_pages, embeddings)\n",
    "        # FAISS vectorstores can also be merged and saved to disk\n",
    "\n",
    "        \"\"\"\n",
    "        Retriever\n",
    "        \"\"\"\n",
    "        # Amount of returned documents k\n",
    "        retriever = db.as_retriever(\n",
    "            search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "\n",
    "        \"\"\"\n",
    "        Chains\n",
    "        \"\"\"\n",
    "\n",
    "        # Define Chain\n",
    "        if own_knowledge:\n",
    "            prompt_template = \"\"\"Use the following pieces of context to find an answer to all the keys given in the question. \\\n",
    "                Give your answer in the form of a dictionary with the keys given in the question. \\\n",
    "                If the answer does not become clear from the context, you can also use your own knowledge. \\\n",
    "                If you use your own knowledge, please indicate this clearly in your answer. \\\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            {question}\n",
    "            Helpful answer:\"\"\"\n",
    "\n",
    "        if not own_knowledge:\n",
    "\n",
    "            prompt_template = \"\"\"Use the following pieces of context to find an answer to all the keys given in the question. \\\n",
    "                Give your answer in the form of a dictionary with the keys given in the question. \\\n",
    "                Do NOT use your own knowledge and give the best possible answer from the context.\\\n",
    "            \n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            {question}\n",
    "            Helpful answer:\"\"\"\n",
    "\n",
    "\n",
    "        PROMPT = PromptTemplate(\n",
    "            template=prompt_template, input_variables=[\"context\",\"question\"]\n",
    "        )\n",
    "\n",
    "        chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "        # Define Chain\n",
    "        qa = RetrievalQA.from_chain_type(\n",
    "            llm=OpenAI(temperature=0),\n",
    "            chain_type=chain_type,\n",
    "            retriever=retriever,\n",
    "            return_source_documents=True,\n",
    "            chain_type_kwargs=chain_type_kwargs\n",
    "        )\n",
    "        \n",
    "\n",
    "        # Run Chain with parameters\n",
    "        result = qa(query)\n",
    "\n",
    "        # Convert string representation of dictionary to an actual dictionary\n",
    "        result_dict = ast.literal_eval(result['result'])\n",
    "\n",
    "        # Get Sources\n",
    "        sources = [(os.path.basename(doc.metadata[\"source\"]), f\"page: {doc.metadata['page']}\") for doc in result['source_documents']]\n",
    "\n",
    "        # Append result to output tables\n",
    "        table_key = (file_name, tuple(sources))\n",
    "        if table_key not in tables:\n",
    "            table_columns = [\"Filename\", \"Sources\"] + list(result_dict.keys())\n",
    "            tables[table_key] = PrettyTable(table_columns)\n",
    "        table_row = [wrap_text(table_key[0]), wrap_text(', '.join([f'{source[0]} {source[1]}' for source in table_key[1]]))] + [wrap_text(str(value)) for value in result_dict.values()]\n",
    "        tables[table_key].add_row(table_row)\n",
    "\n",
    "    # Return output tables\n",
    "    return tables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"model specification, model estimation, model evaluation, model deployment, benchmark models\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Results\n",
    "Use smaller chunk sizes to catch more different part in one prompt. Use at least as many chunks (k) as there are keys in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFilename: file1.pdf\u001b[0m\n",
      "+-----------+----------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "|  Filename |                Sources                 |          model specification          |             model estimation             |             model evaluation             |             model deployment             |             benchmark models            |\n",
      "+-----------+----------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "| file1.pdf | file1.pdf page: 8, file1.pdf page: 13, |    Support vector regression (SVR),   | The weights that were generated by these | Validation is an important step that is  | Based on the saved weighted values, the  |  They tested their model against other  |\n",
      "|           | file1.pdf page: 2, file1.pdf page: 1,  | multiple linear regression (MLR), CRT | four algorithms were used as the inputs  |   used to check the performance of the   | future predictions for 10 minutes and 30 | models supported by ELM, NN, and FLANN. |\n",
      "|           |           file1.pdf page: 1            |   regression tree, and partial least  |     of the Cuckoo search algorithm.      | system by comparing the actual data with |    minutes are done and the system’s     |   They found that between ELM, NN, and  |\n",
      "|           |                                        | squares (PLS) regression methods were |                                          |  predicted data. Here we have used MSE   |         performance is measured.         |   FLANN, ELM shows the most effective   |\n",
      "|           |                                        |      used to train their dataset.     |                                          |  (Mean Squared Error), RMSE (Root Mean   |                                          |              optimization.              |\n",
      "|           |                                        |                                       |                                          |    Square Error), MAPE (Mean Absolute    |                                          |                                         |\n",
      "|           |                                        |                                       |                                          |  Percentage Error), MAE (Mean Absolute   |                                          |                                         |\n",
      "|           |                                        |                                       |                                          |      Error), ARV (Absolute Relative      |                                          |                                         |\n",
      "|           |                                        |                                       |                                          |         Variance), and Theils U.         |                                          |                                         |\n",
      "+-----------+----------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "\n",
      "\u001b[32mFilename: file2.pdf\u001b[0m\n",
      "+-----------+----------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "|  Filename |                Sources                 |          model specification          |             model estimation             |             model evaluation             |             model deployment             |             benchmark models            |\n",
      "+-----------+----------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "| file2.pdf | file2.pdf page: 8, file2.pdf page: 13, |    Support vector regression (SVR),   | The weights that were generated by these | Validation is an important step that is  | Based on the saved weighted values, the  |  They tested their model against other  |\n",
      "|           | file2.pdf page: 2, file2.pdf page: 1,  | multiple linear regression (MLR), CRT | four algorithms were used as the inputs  |   used to check the performance of the   | future predictions for 10 minutes and 30 | models supported by ELM, NN, and FLANN. |\n",
      "|           |           file2.pdf page: 1            |   regression tree, and partial least  |     of the Cuckoo search algorithm.      | system by comparing the actual data with |    minutes are done and the system’s     |   They found that between ELM, NN, and  |\n",
      "|           |                                        | squares (PLS) regression methods were |                                          |  predicted data. Here we have used MSE   |         performance is measured.         |   FLANN, ELM shows the most effective   |\n",
      "|           |                                        |      used to train their dataset.     |                                          |  (Mean Squared Error), RMSE (Root Mean   |                                          |              optimization.              |\n",
      "|           |                                        |                                       |                                          |    Square Error), MAPE (Mean Absolute    |                                          |                                         |\n",
      "|           |                                        |                                       |                                          |  Percentage Error), MAE (Mean Absolute   |                                          |                                         |\n",
      "|           |                                        |                                       |                                          |      Error), ARV (Absolute Relative      |                                          |                                         |\n",
      "|           |                                        |                                       |                                          |         Variance), and Theils U.         |                                          |                                         |\n",
      "+-----------+----------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate Output Table\n",
    "output_table = qa_single_file(folder_path=folder_path, \n",
    "            chain_type=\"stuff\",\n",
    "            chunk_size=500, \n",
    "            query=query, \n",
    "            k=5, \n",
    "            own_knowledge = True, \n",
    "            show_pages=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Print Output Table\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfor\u001b[39;00m table_key, table_value \u001b[39min\u001b[39;00m output_table\u001b[39m.\u001b[39mitems():\n\u001b[0;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(colored(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFilename: \u001b[39m\u001b[39m{\u001b[39;00mtable_key[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(table_value)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output_table' is not defined"
     ]
    }
   ],
   "source": [
    "# Print Output Table\n",
    "for table_key, table_value in output_table.items():\n",
    "    print(colored(f\"Filename: {table_key[0]}\", \"green\"))\n",
    "    print(table_value)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ```qa_single_file_iterated```\n",
    "This iterates over each file **and key** seperately to be even more accurate with the single answers, asking each one the same question. Good for literature overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_single_file_iterated(folder_path, chain_type, chunk_size, queries, k, num_iterations, own_knowledge = False, show_pages=False):\n",
    "\n",
    "    # Define output table.\n",
    "    tables = {}\n",
    "\n",
    "    # Wraptext function for prettytable\n",
    "    def wrap_text(text, width=80):\n",
    "        return textwrap.fill(text, width=width)\n",
    "\n",
    "    \"\"\"\n",
    "    Read-in and split the documents\n",
    "    \"\"\"\n",
    "    # Loop over all files in folder\n",
    "    for file_name in tqdm(os.listdir(folder_path), desc=\"Processing files\",  colour=\"green\", leave=False):\n",
    "        # Define table for filename\n",
    "        tables[file_name] = {}\n",
    "\n",
    "        # Clear all_pages\n",
    "        all_pages = []\n",
    "\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        if file_name.endswith('.pdf'):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif file_name.endswith('.csv'):\n",
    "            loader = CSVLoader(file_path)\n",
    "        elif file_name.endswith('.docx'):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        elif file_name.endswith('.md'):\n",
    "            loader = UnstructuredMarkdownLoader(file_path)\n",
    "        else:\n",
    "            continue  # Skip files with other extensions\n",
    "\n",
    "        file = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_size/2)\n",
    "        pages = text_splitter.split_documents(file)\n",
    "        all_pages.extend(pages)\n",
    "\n",
    "        if show_pages:\n",
    "            print(len(all_pages))\n",
    "            for page in all_pages:\n",
    "                print(page)\n",
    "\n",
    "        \"\"\"\n",
    "        Vectorstores\n",
    "        \"\"\"\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "\n",
    "        db = FAISS.from_documents(all_pages, embeddings)\n",
    "        # FAISS vectorstores can also be merged and saved to disk\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Chains\n",
    "        \"\"\"\n",
    "\n",
    "        # Define Chain\n",
    "        if own_knowledge:\n",
    "            prompt_template = \"\"\"Use the following pieces of context to find an answer to the given question. \\\n",
    "                If the answer does not become clear from the context, you can also use your own knowledge. \\\n",
    "                If you use your own knowledge, please indicate this clearly in your answer. \\\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            Question:\n",
    "            Based on the context, how does the context define and apply: {question}?\n",
    "            Helpful answer:\"\"\"\n",
    "\n",
    "        if not own_knowledge:\n",
    "\n",
    "            prompt_template = \"\"\"Use the following pieces of context to find an answer to the given question. \\\n",
    "                Do NOT use your own knowledge and give the best possible answer from the context.\\\n",
    "            \n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            Question:\n",
    "            Based on the context, how does the context define and apply: {question}?\n",
    "            Helpful answer:\"\"\"\n",
    "\n",
    "\n",
    "        PROMPT = PromptTemplate(\n",
    "            template=prompt_template, input_variables=[\"context\",\"question\"]\n",
    "        )\n",
    "\n",
    "        chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "        \"\"\"\n",
    "        Retriever\n",
    "        \"\"\"\n",
    "        \n",
    "        # Define summary chain\n",
    "        text_splitter = CharacterTextSplitter()\n",
    "        qa_condense = load_summarize_chain(llm=OpenAI(temperature=0), chain_type=\"stuff\")\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        Application of Chains\n",
    "        \"\"\"\n",
    "\n",
    "        # Iterate over each query\n",
    "        for query in queries:\n",
    "\n",
    "            extended_answers = []\n",
    "            unique_sources = set()\n",
    "\n",
    "            for i in range(num_iterations):\n",
    "\n",
    "                # QA chain that is adaptable\n",
    "                # Amount of returned documents k-i -> makes it adaptable. Otherwise, it would always return k documents and the output would be the same.\n",
    "                retriever = db.as_retriever(\n",
    "                    search_type=\"similarity\", search_kwargs={\"k\": k-i})\n",
    "\n",
    "                # Define retrieval chain\n",
    "                qa = RetrievalQA.from_chain_type(\n",
    "                    llm=OpenAI(temperature=0),\n",
    "                    chain_type=chain_type,\n",
    "                    retriever=retriever,\n",
    "                    return_source_documents=True,\n",
    "                    chain_type_kwargs=chain_type_kwargs\n",
    "                )\n",
    "\n",
    "                # Run Chain with parameters\n",
    "                result = qa(query)\n",
    "\n",
    "                # Get Sources\n",
    "                sources = [(doc.page_content, os.path.basename(doc.metadata[\"source\"]), f\"page: {doc.metadata['page']}\") for doc in\n",
    "                        result['source_documents']]\n",
    "\n",
    "                # Append result to extended_answers\n",
    "                extended_answers.append(result['result'])\n",
    "\n",
    "                # Add sources to the unique_sources set\n",
    "                unique_sources.update(sources)\n",
    "\n",
    "\n",
    "\n",
    "            # Combine extended_answers\n",
    "            combined_result = ' '.join(extended_answers)\n",
    "\n",
    "            # Run the qa function on the combined_result (summary)\n",
    "            texts = text_splitter.split_text(combined_result)\n",
    "            docs = [Document(page_content=t) for t in texts[:3]]\n",
    "            \n",
    "            condensed_result = str(qa_condense.run(docs))\n",
    "\n",
    "            # Combine unique_sources\n",
    "            combined_sources = {tuple([source[1], source[2]]): source[0] for source in unique_sources}\n",
    "\n",
    "\n",
    "            # Store the results in the tables dictionary\n",
    "            tables[file_name][query] = {\n",
    "                \"combined_results\": combined_result,\n",
    "                \"condensed_result\": condensed_result,\n",
    "                \"combined_sources\": combined_sources\n",
    "            }\n",
    "\n",
    "\n",
    "    # Return output tables\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"model specification\", \"model estimation\", \"model evaluation\", \"model deployment\", \"benchmark models\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Results\n",
    "Use smaller chunk sizes to catch more different part in one prompt. Use at least as many chunks (k) as there are keys in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                5.98s/it]\r"
     ]
    }
   ],
   "source": [
    "# Generate Output Table\n",
    "output_table = qa_single_file_iterated(folder_path=folder_path, \n",
    "            chain_type=\"stuff\",\n",
    "            chunk_size=500, \n",
    "            queries=queries, \n",
    "            k=8, \n",
    "            num_iterations=4,\n",
    "            own_knowledge = False, \n",
    "            show_pages=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: file1.pdf\n",
      "+------------------+------------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+\n",
      "| Type             | model specification                      | model estimation                         | model evaluation                         | model deployment                         | benchmark models                         |\n",
      "+==================+==========================================+==========================================+==========================================+==========================================+==========================================+\n",
      "| Combined_results | Model specification is defined as the    | Model estimation is the process of       | Model evaluation is defined as the       | Model deployment is the process of       | Benchmark models are used in the         |\n",
      "|                  | process of selecting the appropriate     | using regression techniques to compare   | process of comparing the actual data     | making a model available for use in      | context to compare the performance of    |\n",
      "|                  | model and parameters for a given dataset | actual data with predicted data in order | with predicted data using performance    | production. In the context, model        | the proposed hybrid model against a      |\n",
      "|                  | in order to make accurate predictions.   | to measure the performance of the        | matrices such as MSE, RMSE, MAE, and     | deployment is discussed in terms of the  | simple statistical model that uses the   |\n",
      "|                  | In this context, the model specification | system. This is done by calculating the  | R-squared score to measure the           | evaluation of the system's performance   | simple moving average of the previous    |\n",
      "|                  | is based on the regression technique     | MSE, RMSE, MAE, and R-squared (R2)       | performance of the system. The context   | by comparing the actual data with the    | 20-days closing price. The performance   |\n",
      "|                  | combined with the cuckoo search          | values.  Model estimation is the process | applies model evaluation by comparing    | predicted data. This is done by          | of the proposed model is compared to the |\n",
      "|                  | algorithm, and the parameters are        | of using regression techniques to train  | the proposed models against a standalone | measuring the performance of the system  | standalone LSTM model, a standalone GRU  |\n",
      "|                  | determined by the four major currency    | a dataset and generate weights that can  | GRU, a standalone LSTM, and a            | using metrics such as MSE, RMSE, MAE,    | model, and the simple moving average     |\n",
      "|                  | pairs: EUR/USD, GBP/USD, USD/CAD, and    | be used to predict future values. The    | statistical model based on the moving    | and R-squared value. Additionally, the   | (SMA) based statistical model in terms   |\n",
      "|                  | USD/CHF. The model is then validated     | context describes how multiple linear    | average technique.  Model evaluation is  | context discusses the use of hybrid      | of MSE, RMSE, MAE, and 𝑅2 scores. The    |\n",
      "|                  | using MSE, RMSE, MAE, and R-squared      | regression (MLR), support vector         | defined as the process of comparing the  | models, which combine multiple models,   | comparison of the models is used to      |\n",
      "|                  | values.              The context defines | regression (SVR), partial least squares  | actual data with the predicted data to   | to improve the accuracy and reduce       | determine which model is the least risky |\n",
      "|                  | model specification as the combination   | (PLS) regression, and cuckoo search      | measure the performance of the system.   | uncertainty.  Model deployment is the    | and most reliable.  Benchmark models are |\n",
      "|                  | of regression techniques with the cuckoo | algorithms were used to train a dataset  | It is applied by using performance       | process of making the model available    | used as a comparison to measure the      |\n",
      "|                  | search algorithm to predict the exchange | and generate weights for predicting      | matrices such as MSE, RMSE, MAE, and     | for use in a production environment. In  | performance of the proposed model. In    |\n",
      "|                  | market. The model is inspired by the     | future values. The context also          | R-squared score.  Model evaluation is    | the context, model deployment is used to | this context, the benchmark models are   |\n",
      "|                  | autoregressive moving average (ARMA)     | describes how the performance of the     | defined in the context as the process of | compare the performance of the proposed  | the standalone LSTM model, the           |\n",
      "|                  | model and is tested against other models | system was measured using MSE, RMSE,     | comparing the actual data with the       | model against other models, such as ELM, | standalone GRU model, and the simple     |\n",
      "|                  | such as ELM, NN, and FLANN. The          | MAE, and R-squared (R2) values.  Model   | predicted data using performance         | NN, and FLANN. The performance of the    | moving average (SMA) based statistical   |\n",
      "|                  | performance of the system is measured    | estimation is the process of measuring   | matrices such as MSE, RMSE, MAE, and     | model is measured using metrics such as  | model. The performance of the proposed   |\n",
      "|                  | using MSE, RMSE, MAE, and R-squared (R2) | the performance of a system by comparing | R-squared score. This process is used to | MSE, RMSE, MAE, and R-squared value. The | model is compared to these benchmark     |\n",
      "|                  | values.  The context defines model       | the actual data with the predicted data  | measure the performance of the system    | model is also tested for future          | models in terms of MSE, RMSE, MAE, and   |\n",
      "|                  | specification as the combination of      | using metrics such as MSE, RMSE, MAE,    | and to compare the performance of the    | predictions for 10 minutes and 30        | 𝑅2 scores.  Benchmark models are used as |\n",
      "|                  | regression techniques with the cuckoo    | and R-squared (R2) value.  Model         | proposed models against other models     | minutes.  Model deployment is defined in | a comparison to measure the performance  |\n",
      "|                  | search algorithm used to develop a       | estimation is the process of measuring   | such as standalone LSTM, standalone GRU, | the context as the process of            | of the proposed model. In this context,  |\n",
      "|                  | hybrid model for currency exchange       | the performance of a system by comparing | and SMA based statistical model.  Model  | implementing the proposed system         | the benchmark models are the standalone  |\n",
      "|                  | market prediction. The model is inspired | the actual data with the predicted data  | evaluation is defined as the process of  | architecture and testing the system's    | LSTM model, the standalone GRU model,    |\n",
      "|                  | by the autoregressive moving average     | using metrics such as MSE, RMSE, MAE,    | comparing the actual data with predicted | performance by comparing the actual data | and the simple moving average (SMA)      |\n",
      "|                  | (ARMA) model and is tested against other | and R-squared (R2) value.                | data using performance matrices such as  | with the predicted data. This is done by | based statistical model. The performance |\n",
      "|                  | models such as ELM, NN, and FLANN.       |                                          | MSE, RMSE, MAE, and R-squared score to   | measuring the performance of the system  | of the proposed model is compared to     |\n",
      "|                  | Model specification is defined as the    |                                          | measure the performance of the system.   | using MSE, RMSE, MAE, and R-squared (R2) | these benchmark models in terms of MSE,  |\n",
      "|                  | process of selecting the appropriate     |                                          |                                          | values. Additionally, the context also   | RMSE, MAE, and 𝑅2 scores.  Benchmark     |\n",
      "|                  | model for a given dataset. In this       |                                          |                                          | mentions that the hybrid models          | models are used to compare the           |\n",
      "|                  | context, a hybrid model based on the     |                                          |                                          | performed better than stand-alone        | performance of the proposed hybrid model |\n",
      "|                  | regression technique was developed by    |                                          |                                          | models, which further motivates the use  | against a simple statistical model. The  |\n",
      "|                  | Said, Omar, and Aziz which combined      |                                          |                                          | of a combination of GRU and LSTM for     | benchmark models used in the context are |\n",
      "|                  | regression techniques with the cuckoo    |                                          |                                          | model deployment.  Model deployment is   | the standalone LSTM model, a standalone  |\n",
      "|                  | search algorithm. The model was inspired |                                          |                                          | defined in the context as the process of | GRU model, and a simple moving average   |\n",
      "|                  | by the autoregressive moving average     |                                          |                                          | implementing the proposed system         | (SMA) based statistical model. The       |\n",
      "|                  | (ARMA) model and the dataset was         |                                          |                                          | architecture and validating the          | performance of the proposed model is     |\n",
      "|                  | prepared with historical data of the     |                                          |                                          | performance of the system by comparing   | compared to these benchmark models in    |\n",
      "|                  | USD/EUR currency pair. Support vector    |                                          |                                          | the actual data with the predicted data. | terms of MSE, RMSE, MAE, and 𝑅2 scores.  |\n",
      "|                  | regression (SVR), multiple linear        |                                          |                                          | This is done by measuring the            |                                          |\n",
      "|                  | regression, and nonparametric self-      |                                          |                                          | performance of the system using MSE,     |                                          |\n",
      "|                  | organising modelling approach were also  |                                          |                                          | RMSE, MAE, and R-squared (R2) value.     |                                          |\n",
      "|                  | used.                                    |                                          |                                          |                                          |                                          |\n",
      "+------------------+------------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+\n",
      "| Condensed_result | Model specification is the process of    | Model estimation is the process of       | Model evaluation is the process of       | Model deployment is the process of       | Benchmark models are used to compare     |\n",
      "|                  | selecting the appropriate model and      | using regression techniques to train a   | comparing the actual data with the       | making a model available for use in      | the performance of the proposed hybrid   |\n",
      "|                  | parameters for a given dataset in order  | dataset and generate weights for         | predicted data using performance         | production. It involves evaluating the   | model against a simple statistical       |\n",
      "|                  | to make accurate predictions. In this    | predicting future values. The            | matrices such as MSE, RMSE, MAE, and     | system's performance by comparing the    | model. The benchmark models used are the |\n",
      "|                  | context, a hybrid model was developed by | performance of the system is then        | R-squared score to measure the           | actual data with the predicted data,     | standalone LSTM model, a standalone GRU  |\n",
      "|                  | Said, Omar, and Aziz which combined      | measured by comparing the actual data    | performance of the system. It is used to | using metrics such as MSE, RMSE, MAE,    | model, and a simple moving average (SMA) |\n",
      "|                  | regression techniques with the cuckoo    | with the predicted data using metrics    | compare the performance of the proposed  | and R-squared value. Hybrid models,      | based statistical model. The performance |\n",
      "|                  | search algorithm and was tested against  | such as MSE, RMSE, MAE, and R-squared    | models against other models such as      | which combine multiple models, are used  | of the proposed model is compared to     |\n",
      "|                  | other models such as ELM, NN, and FLANN. | (R2) value.                              | standalone LSTM, standalone GRU, and SMA | to improve accuracy and reduce           | these benchmark models in terms of MSE,  |\n",
      "|                  | The model was validated using MSE, RMSE, |                                          | based statistical model.                 | uncertainty. The performance of the      | RMSE, MAE, and 𝑅2 scores to determine    |\n",
      "|                  | MAE, and R-squared values and was        |                                          |                                          | model is tested for future predictions   | which model is the least risky and most  |\n",
      "|                  | prepared with historical data of the     |                                          |                                          | for 10 minutes and 30 minutes.           | reliable.                                |\n",
      "|                  | USD/EUR currency pair.                   |                                          |                                          |                                          |                                          |\n",
      "+------------------+------------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+\n",
      "| Combined_sources | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 9\u001b[0m                        | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 2\u001b[0m                        | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 9\u001b[0m                        | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 3\u001b[0m                        | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 9\u001b[0m see                    |\n",
      "|                  | 5.1.1. EUR/USD   For the EUR/USD         | M.S. Islam and E. Hossain Soft Computing | M.S. Islam and E. Hossain Soft Computing | M.S. Islam and E. Hossain Soft Computing | if our proposed  model improves  the     |\n",
      "|                  | currency  pair, we validated  the model  | Letters 3 (2021) 100009  Fig. 1. Simple  | Letters 3 (2021) 100009  Fig. 11.        | Letters 3 (2021) 100009  Fig. 3.         | overall performance  and can  outperform |\n",
      "|                  | against   14886 samples  for our 10-mins | architecture  of our proposed  pipeline. | Distribution  of diﬀerence  between  ac- | Distribution  of diﬀerences  between     | any of these algorithms  as the whole    |\n",
      "|                  | model and 3723 samples  for our 30-mins  | USDINR.  They tested their model against | tual and predicted  curve for USD/CAD    | ac-  tual and predicted  curve for       | experiment  will be  meaningless  if the |\n",
      "|                  | model that is 20% of our total data      | other models supported  by  ELM, NN, and | 10-mins   timeframe.   closing price of  | EUR/USD  10-mins   timeframe.   provided | system provides  same performance  or    |\n",
      "|                  | respectively.  The model is trained      | FLANN.  They found that between  ELM,    | each currency  pair before 10 minutes    | more stability  and accuracy  in         | worse than the  individual  models and   |\n",
      "|                  | using the rest of the data. Figs. 3 and  | NN, and FLANN,   ELM shows the most      | and 30 minutes   than the actual time.   | predicting  the rates. The analy-  sis   | its not possible  to understand  the     |\n",
      "|                  | 4 present  the distribution  of dif-     | eﬀective  optimization.  Consistent      | Also, we have compared  our proposed     | showed  that hybrid models performed     | diﬀerence  with-  out proper comparison. |\n",
      "|                  | ferences  between  actual and predicted  | with their eval-  uation data, for MAPE  | models  against  a standalone  GRU, a    | better than stand-alone  mod-  els.      | Another  reason for choosing  these two  |\n",
      "|                  | curve provided  in Figs. 5 and  6 ,      | evaluation  ELM DE provides  rock bottom | standalone  LSTM, and a statistical      | Hybrid models provided  more accuracy    | models is  their performance,  which is  |\n",
      "|                  | respectively.  The x -axis represents    | error.  For MAE, ARV, and Theils U       | model  that is based on the moving       | and also reduced  uncer-  tainty. This   | better than other deep learning          |\n",
      "|                  | the diﬀerence  between  the actual       | models ELM TLBO, ELM PSO and ELM Jaya    | average  technique.   5.1. Performance   | also motivates  us to use a combination  | approaches  \u001b[31mfile1.pdf\u001b[0m                    |\n",
      "|                  | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 15\u001b[0m and                   | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 10\u001b[0m                       | evaluation  \u001b[31mfile1.pdf\u001b[0m                    | of GRU and LSTM  \u001b[31mfile1.pdf\u001b[0m               | \u001b[31mpage: 14\u001b[0m our proposed  hybrid            |\n",
      "|                  | nonparametric  self-organising           | model, these values are 0.00084,         | \u001b[31mpage: 2\u001b[0m ELM shows the most               | \u001b[31mpage: 9\u001b[0m see if our proposed              | model against  a simple statistical      |\n",
      "|                  | modelling  approach,  Expert Syst. Appl. | 0.02895,  0.01448  and 0.93690  respec-  | eﬀective  optimization.  Consistent      | model improves  the overall performance  | model that uses  the simple moving       |\n",
      "|                  | 36 (10)  (2009) 12001–12011,  doi:       | tively. The actual vs predicted  value   | with their eval-  uation data, for MAPE  | and can  outperform  any of these        | average  of the previous  20-days        |\n",
      "|                  | 10.1016/j.eswa.2009.03.057  .  [4] R.D.  | curves are provided  in Figs. 7 and  8 . | evaluation  ELM DE provides  rock bottom | algorithms  as the whole experiment      | closing price. Al-  though,  this model  |\n",
      "|                  | Huang, R.W. Masulis, Fx spreads and      | The x-axis indicates  the number  of     | error.  For MAE, ARV, and Theils U       | will be  meaningless  if the system      | produces  less error for EUR/USD  and    |\n",
      "|                  | dealer competition  across the 24-hour   | test samples  (14871  for 10-mins        | models ELM TLBO, ELM PSO and ELM Jaya    | provides  same performance  or worse     | USD/CHF  in  30-mins  timeframe,  but it |\n",
      "|                  | trading day, Rev. Financ. Stud. 12 (1)   | model and 37224 samples  for 30-mins     | provided  the most eﬀective  result      | than the  individual  models and its not | has a very high risk associated  with    |\n",
      "|                  | (1999) 61–93, doi: 10.1093/rfs/12.1.61   | model) that have been used for           | respectively.  For FOREX trading  strat- | possible  to understand  the diﬀerence   | it. In  terms of risk associated  with   |\n",
      "|                  | .  [5] S. Masry, A. Dupuis, R. Olsen, E. | prediction.  The actual closing values   | egy optimization,  a genetic  algorithm  | with-  out proper comparison.  Another   | the return, the proposed  model          |\n",
      "|                  | Tsang, Time zone normalization  of fx    | of the currency  pairs are marked   by   | was employed  by Galeshchuk  and         | reason for choosing  these two models is | maintains   its superiority  among all   |\n",
      "|                  | seasonality,   Quant. Finance 13 (7)     | yellow color and model predicted         | Mukherjee  [34] to evolve a special set  | their performance,  which is better than | the models for both timeframes.          |\n",
      "|                  | (2013) 1115–1123,  doi:                  | closing values are marked  by blue       | of proﬁtable  trading  rules inspired    | other deep learning  approaches          | Although  the  \u001b[31mfile1.pdf\u001b[0m                 |\n",
      "|                  | 10.1080/14697688.2013.773458  .          | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 1\u001b[0m sion                   | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 8\u001b[0m the                    | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 2\u001b[0m M.S.                   | \u001b[31mpage: 13\u001b[0m Proposed  Model                 |\n",
      "|                  | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 2\u001b[0m M.S.                   | (MLR), CRT regression  tree, and partial | future predictions  for 10 minutes  and  | Islam and E. Hossain Soft Computing      | 0.99205 0.93690 0.99287 0.98159  LSTM    |\n",
      "|                  | Islam and E. Hossain Soft Computing      | least squares  (PLS) regres-  sion       | 30 minutes  are done and the  system’s   | Letters 3 (2021) 100009  Fig. 1. Simple  | 0.98358 0.92664 0.59762 0.30702  GRU     |\n",
      "|                  | Letters 3 (2021) 100009  Fig. 1. Simple  | methods  were used to train their        | performance  is measured.   4.4. Model   | architecture  of our proposed  pipeline. | 0.99052 0.68449 0.90486 0.98010  SMA     |\n",
      "|                  | architecture  of our proposed  pipeline. | dataset.  The weights  that were         | validation   Validation  is an important | USDINR.  They tested their model against | 0.39487 0.05839 0.01325 0.21750  and     |\n",
      "|                  | USDINR.  They tested their model against | generated  by these four algorithms      | step that is used to check the           | other models supported  by  ELM, NN, and | 0.21750,  respectively)  among all the   |\n",
      "|                  | other models supported  by  ELM, NN, and | were used as the inputs of the Cuckoo    | performance   of the system by comparing | FLANN.  They found that between  ELM,    | models and thus have a huge  risk        |\n",
      "|                  | FLANN.  They found that between  ELM,    | search algorithm.  The experiment  was   | the actual data with predicted  data.    | NN, and FLANN,   ELM shows the most      | associated  with it. Table 9 and 10 show |\n",
      "|                  | NN, and FLANN,   ELM shows the most      | done with two years of histori-   cal    | Here we have used MSE (Mean Squared      | eﬀective  optimization.  Consistent      | the comparison  of the mod-  els in      |\n",
      "|                  | eﬀective  optimization.  Consistent      | data. Multiple  linear regression  (MLR) | Error), RMSE (Root Mean Square Error),   | with their eval-  uation data, for MAPE  | terms of 𝑅 2 scores for 10-mins  and     |\n",
      "|                  | with their eval-  uation data, for MAPE  | provided  better results than  SVR, PLS, | MAE (Mean Absolute  Error), and          | evaluation  ELM DE provides  rock bottom | 30-mins  timeframe  respec-  tively. Our |\n",
      "|                  | evaluation  ELM DE provides  rock bottom | and CRT. Their model outperformed  other | R-squared  ( 𝑅 2 ) value for measuring   | error.  For MAE, ARV, and Theils U       | proposed  model produces  higher 𝑅 2     |\n",
      "|                  | error.  For MAE, ARV, and Theils U       | regression  algo-  \u001b[31mfile1.pdf\u001b[0m             | the  performance  of our system.  Among  | models ELM TLBO, ELM PSO and ELM Jaya    | scores than both of the                  |\n",
      "|                  | models ELM TLBO, ELM PSO and ELM Jaya    | \u001b[31mpage: 8\u001b[0m the future predictions           | them in MSE and RMSE, the error          | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 1\u001b[0m                        | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 10\u001b[0m                       |\n",
      "|                  | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 10\u001b[0m                       | for 10 minutes  and 30 minutes  are done | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 3\u001b[0m                        | vector machine  (SVM). SVM was           | model, these values are 0.00084,         |\n",
      "|                  | model, these values are 0.00084,         | and the  system’s  performance  is       | system.  to check the performance  of    | implemented  in both individual  and     | 0.02895,  0.01448  and 0.93690  respec-  |\n",
      "|                  | 0.02895,  0.01448  and 0.93690  respec-  | measured.   4.4. Model validation        | the system,  two diﬀerent  algorithms    | hybrid systems  with prediction          | tively. The actual vs predicted  value   |\n",
      "|                  | tively. The actual vs predicted  value   | Validation  is an important  step that   | Shuﬄed  frog leaping  algorithm  and     | capabilities.  Thuy and Vuong [28] pro-  | curves are provided  in Figs. 7 and  8 . |\n",
      "|                  | curves are provided  in Figs. 7 and  8 . | is used to check the performance   of    | Particle  Swarm optimization  algo-      | posed a model for foreign exchange       | The x-axis indicates  the number  of     |\n",
      "|                  | The x-axis indicates  the number  of     | the system by comparing  the actual data | rithm were used. The result showed  that | prediction  using SVM. They used  the    | test samples  (14871  for 10-mins        |\n",
      "|                  | test samples  (14871  for 10-mins        | with predicted  data. Here we have used  | this proposed  model performed   better  | EUR/USD  currency  pair for their models | model and 37224 samples  for 30-mins     |\n",
      "|                  | model and 37224 samples  for 30-mins     | MSE (Mean Squared  Error), RMSE (Root    | than both of the compared  algorithms.   | implementation.  They used  the cross-   | model) that have been used for           |\n",
      "|                  | model) that have been used for           | Mean Square Error),  MAE (Mean Absolute  | For RMSE the error rate  for USD/CAD     | validation  method  for their data-set   | prediction.  The actual closing values   |\n",
      "|                  | prediction.  The actual closing values   | Error), and R-squared  ( 𝑅 2 ) value for | and USD/JPY  currency  pairs was between | and divided  the results  into two       | of the currency  pairs are marked   by   |\n",
      "|                  | of the currency  pairs are marked   by   | measuring  the  performance  of our      | 0.04–0.05  and  for USD/CHF  the range   | categories  positive  output and         | yellow color and model predicted         |\n",
      "|                  | yellow color and model predicted         | system.  Among  them in MSE and RMSE,    | was between  0.03–0.04.  Similar         | negative  output.  They used ac-         | closing values are marked  by blue       |\n",
      "|                  | closing values are marked  by blue       | the error  \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage:               | approach  was  \u001b[31mfile1.pdf\u001b[0m                 | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 8\u001b[0m the                    | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 1\u001b[0m                        |\n",
      "|                  | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 1\u001b[0m                        | 9\u001b[0m color, and the model predicted         | \u001b[31mpage: 0\u001b[0m data from January  1,            | future predictions  for 10 minutes  and  | exchange  market prediction.  A hybrid   |\n",
      "|                  | searchers  are trying to come up with    | closing values are marked  by blue       | 2019 to June 30, 2020 as a proof-of-     | 30 minutes  are done and the  system’s   | model based on the regression            |\n",
      "|                  | new models to predict the nature  of     | color.  The y-axis indicates  the unit   | concept.  The performance  of the model  | performance  is measured.   4.4. Model   | technique  was developed  by Said, Omar, |\n",
      "|                  | this market.  While there are many       | value of this pair which in this case is | is validated   using MSE, RMSE, MAE, and | validation   Validation  is an important | and Aziz who used a combi-  nation of    |\n",
      "|                  | machine  learning  and deep learn-  ing  | the  normalized  closing price of        | 𝑅 2 score. Moreover,  we have compared   | step that is used to check the           | regression  techniques  with the cuckoo  |\n",
      "|                  | approaches  used in ﬁnance,  there is a  | EUR/USD  currency  pair. The ﬂuctuation  | the performance  of our model against a  | performance   of the system by comparing | search algorithm  [17] .  Their model    |\n",
      "|                  | constant  competition  where  traders    | in  the curve indicates  the ups and     | standalone  LSTM model, a standalone     | the actual data with predicted  data.    | was inspired  by the autoregressive      |\n",
      "|                  | look for new techniques  to outperform   | downs of the closing prices.  The graphs | GRU model and simple moving average      | Here we have used MSE (Mean Squared      | moving  average  (ARMA)   model and they |\n",
      "|                  | the market.  This makes  the novel       | clearly show how accurate  the           | (SMA) based statistical  model  where    | Error), RMSE (Root Mean Square Error),   | prepared  their dataset with historical  |\n",
      "|                  | approaches  more demanding  as their     | predictions  are: actual  and predicted  | the proposed  hybrid GRU-LSTM  model     | MAE (Mean Absolute  Error), and          | data of USD/EUR   currency  pair.        |\n",
      "|                  | uniqueness  helps traders  to meet their | values almost overlap  with each other.  | outperforms  all models for 10-mins      | R-squared  ( 𝑅 2 ) value for measuring   | Support  vector regression  (SVR),       |\n",
      "|                  | desire in a particular  way.  The rest   | The MSE, RMSE,  and MAE scores of our    | timeframe  and for 30-mins               | the  performance  of our system.  Among  | multiple  linear regres-                 |\n",
      "|                  | of the article is organized  as follows. | model for EUR/USD  10-mins  pairs are    |                                          | them in MSE and RMSE, the error          | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 12\u001b[0m                       |\n",
      "|                  | Section  2 presents  \u001b[31mfile1.pdf\u001b[0m           | 0.00001,                                 |                                          | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 7\u001b[0m                        | USD/CAD  10-mins  performance            |\n",
      "|                  | \u001b[31mpage: 8\u001b[0m the future predictions           |                                          |                                          | system architecture  of our proposed     | comparison.   Models MSE RMSE MAE        |\n",
      "|                  | for 10 minutes  and 30 minutes  are done |                                          |                                          | system.   4.1. Data collection   The     | Proposed  Model 0.00004 0.00597 0.00387  |\n",
      "|                  | and the  system’s  performance  is       |                                          |                                          | dataset was collected  from Histdata     | LSTM 0.00005 0.00686 0.00464  GRU        |\n",
      "|                  | measured.   4.4. Model validation        |                                          |                                          | [65] website.  Data was col-  lected for | 0.00041 0.02024 0.01721  SMA 0.00008     |\n",
      "|                  | Validation  is an important  step that   |                                          |                                          | four major currency  pairs: EUR/USD      | 0.00936 0.00788  Table 4  USD/CHF        |\n",
      "|                  | is used to check the performance   of    |                                          |                                          | [66] , GBP/USD  [67] ,  USD/CAD  [68] ,  | 10-mins  performance  comparison.        |\n",
      "|                  | the system by comparing  the actual data |                                          |                                          | and USD/CHF  [69] . We have collected    | Model MSE RMSE MAE  Proposed  Model      |\n",
      "|                  | with predicted  data. Here we have used  |                                          |                                          | two years of his-  torical time series   | 0.00001 0.00362 0.00261  LSTM 0.00001    |\n",
      "|                  | MSE (Mean Squared  Error), RMSE (Root    |                                          |                                          | data from 1st January,  2017 to 31st     | 0.00385 0.00281  GRU 0.00036 0.01888     |\n",
      "|                  | Mean Square Error),  MAE (Mean Absolute  |                                          |                                          | December,  2018  for our 10 minutes      | 0.01516  SMA 0.00006 0.00825 0.00649     |\n",
      "|                  | Error), and R-squared  ( 𝑅 2 ) value for |                                          |                                          | prediction  model and from 1st January,  | Table 5  EUR/USD  30-mins  performance   |\n",
      "|                  | measuring  the  performance  of our      |                                          |                                          | 2019 to 30th                             | comparison.   Models MSE RMSE MAE        |\n",
      "|                  | system.  Among  them in MSE and RMSE,    |                                          |                                          |                                          | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 0\u001b[0m                        |\n",
      "|                  | the error  \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage:               |                                          |                                          |                                          | standalone  LSTM model, a standalone     |\n",
      "|                  | 7\u001b[0m system architecture  of our            |                                          |                                          |                                          | GRU model and simple moving average      |\n",
      "|                  | proposed  system.   4.1. Data collection |                                          |                                          |                                          | (SMA) based statistical  model  where    |\n",
      "|                  | The dataset was collected  from Histdata |                                          |                                          |                                          | the proposed  hybrid GRU-LSTM  model     |\n",
      "|                  | [65] website.  Data was col-  lected for |                                          |                                          |                                          | outperforms  all models for 10-mins      |\n",
      "|                  | four major currency  pairs: EUR/USD      |                                          |                                          |                                          | timeframe  and for 30-mins   timeframe   |\n",
      "|                  | [66] , GBP/USD  [67] ,  USD/CAD  [68] ,  |                                          |                                          |                                          | provides  the best result for GBP/USD    |\n",
      "|                  | and USD/CHF  [69] . We have collected    |                                          |                                          |                                          | and USD/CAD  currency  pairs in terms of |\n",
      "|                  | two years of his-  torical time series   |                                          |                                          |                                          | MSE, RMSE, and MAE  performance          |\n",
      "|                  | data from 1st January,  2017 to 31st     |                                          |                                          |                                          | metrics.  But in terms of 𝑅 2 score, our |\n",
      "|                  | December,  2018  for our 10 minutes      |                                          |                                          |                                          | system outperforms  all compared  models |\n",
      "|                  | prediction  model and from 1st January,  |                                          |                                          |                                          | and thus proves  itself as the least     |\n",
      "|                  | 2019 to 30th                             |                                          |                                          |                                          | risky model among all.  1. Introduction  |\n",
      "+------------------+------------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Wraptext function for prettytable\n",
    "def wrap_text(text, width=40):\n",
    "    return \"\\n\".join(textwrap.wrap(text, width=width))\n",
    "\n",
    "# Create a table with predefined row names\n",
    "row_names = [\"combined_results\", \"condensed_result\", \"combined_sources\"]\n",
    "\n",
    "# After processing all files, create and print the tables\n",
    "for file_name, queries_results in output_table.items():\n",
    "    # Create a table with 'Type' as the leftmost column\n",
    "    table_data = [[\"Type\"] + queries]\n",
    "    \n",
    "    # Add rows to the table\n",
    "    for result_type in row_names:\n",
    "        row = [result_type.capitalize()]\n",
    "        for query in queries:\n",
    "            if result_type == \"combined_sources\":\n",
    "                sources_str = \"\\n\".join([f\"\\n{colored(k[0], 'red')} {colored(k[1], 'red')}\\n{v}\" for k, v in queries_results[query][result_type].items()])\n",
    "                row.append(wrap_text(sources_str))\n",
    "            else:\n",
    "                row.append(wrap_text(queries_results[query][result_type]))\n",
    "        table_data.append(row)\n",
    "\n",
    "    # Print the table for the current file_name with a separator between rows\n",
    "    print(f\"File: {file_name}\\n{tabulate(table_data, headers='firstrow', tablefmt='grid')}\\n{'=' * 80}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ```qa_all_at_once```\n",
    "Searches for the answer through all documents. Can also take the chat history into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_all_at_once(folder_path, chain_type, chunk_size, query, k, own_knowledge = False, show_pages=False):\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Read-in and split the documents\n",
    "    \"\"\"\n",
    "    all_pages = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        if file_name.endswith('.pdf'):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif file_name.endswith('.csv'):\n",
    "            loader = CSVLoader(file_path)\n",
    "        elif file_name.endswith('.docx'):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        elif file_name.endswith('.md'):\n",
    "            loader = UnstructuredMarkdownLoader(file_path)\n",
    "        else:\n",
    "            continue  # Skip files with other extensions\n",
    "\n",
    "        file = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_size/2)\n",
    "        pages = text_splitter.split_documents(file)\n",
    "        all_pages.extend(pages)\n",
    "\n",
    "    if show_pages:\n",
    "        print(len(all_pages))\n",
    "        for page in all_pages:\n",
    "            print(page)\n",
    "\n",
    "    \"\"\"\n",
    "    Vectorstores\n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    db = FAISS.from_documents(all_pages, embeddings)\n",
    "    # FAISS vectorstores can also be merged and saved to disk\n",
    "\n",
    "    \"\"\"\n",
    "    Retriever\n",
    "    \"\"\"\n",
    "    # Amount of returned documents k\n",
    "    retriever = db.as_retriever(\n",
    "        search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "\n",
    "    \"\"\"\n",
    "    Chains\n",
    "    \"\"\"\n",
    "\n",
    "    # Define Chain\n",
    "    if own_knowledge:\n",
    "        prompt_template = \"\"\"Use the following pieces of chat history and context to answer the question at the end. \\\n",
    "            If the answer does not become clear from the context, you can also use your own knowledge. \\\n",
    "            If you use your own knowledge, please indicate this clearly in your answer. \\\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        {question}\n",
    "        Helpful answer:\"\"\"\n",
    "\n",
    "    if not own_knowledge:\n",
    "\n",
    "        prompt_template = \"\"\"Use the following pieces of chat history and context to answer the question at the end. \\\n",
    "            Do NOT use your own knowledge and give the best possible answer from the context.\\\n",
    "        \n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        {question}\n",
    "        Helpful answer:\"\"\"\n",
    "\n",
    "\n",
    "    PROMPT = PromptTemplate(\n",
    "        template=prompt_template, input_variables=[\"context\",\"question\"]\n",
    "    )\n",
    "\n",
    "    chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "    # Define Chain\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=OpenAI(temperature=0),\n",
    "        chain_type=chain_type,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs=chain_type_kwargs\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Run Chain with parameters\n",
    "    result = qa(query)\n",
    "\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the chat history: \n",
      " {} \n",
      "And this is the current question: \n",
      " What is a LSTM model?.\n"
     ]
    }
   ],
   "source": [
    "# Define the Query\n",
    "query = \"What is a LSTM model?\"\n",
    "\n",
    "# Update the query with the Chat History\n",
    "query_with_context = f\"This is the chat history: \\n {str(chat_history)} \\nAnd this is the current question: \\n {query}.\"\n",
    "print(query_with_context)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Results\n",
    "In case you do not want the chat history to be part of the prompt, change ```query=query```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------\n",
      "\u001b[32mAnswer:\u001b[0m\n",
      "--------------------------------------------------------------------\n",
      "\n",
      " A Long Short-Term Memory (LSTM) model is a type of Recurrent Neural Network\n",
      "(RNN) that is capable of learning long-term dependencies. It is composed of four\n",
      "layers: an input layer, a memory unit, a cell state, and an output layer. The\n",
      "key component of the LSTM is the cell state, which runs straight down the entire\n",
      "timesteps with only minor but important interactions. LSTM can add or remove\n",
      "information from the cell state using several gates, each of which is made of a\n",
      "sigmoid neural network layer. These sigmoid layers produce output numbers\n",
      "between 0 and 1, which represent how much information is kept or removed from\n",
      "the cell state. LSTM models can be trained using an optimization algorithm like\n",
      "gradient descent on a set of training sequences.\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\u001b[32mSources:\u001b[0m\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "('file1.pdf', 'page: 5')\n",
      "('file2.pdf', 'page: 5')\n",
      "('file1.pdf', 'page: 5')\n",
      "('file2.pdf', 'page: 5')\n"
     ]
    }
   ],
   "source": [
    "# Get Results\n",
    "result = qa_all_at_once(folder_path=folder_path, \n",
    "            chain_type=\"stuff\",\n",
    "            chunk_size=1000, \n",
    "            query=query_with_context, \n",
    "            k=4, \n",
    "            own_knowledge = True, \n",
    "            show_pages=False)\n",
    "\n",
    "# Append Queries and Answers to Chat History\n",
    "chat_history[query] = result['result']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Define Sources\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m sources \u001b[39m=\u001b[39m [(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(doc\u001b[39m.\u001b[39mmetadata[\u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m]), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpage: \u001b[39m\u001b[39m{\u001b[39;00mdoc\u001b[39m.\u001b[39mmetadata[\u001b[39m'\u001b[39m\u001b[39mpage\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m result[\u001b[39m'\u001b[39m\u001b[39msource_documents\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m      4\u001b[0m \u001b[39m# Sort sources by filename and page number\u001b[39;00m\n\u001b[0;32m      5\u001b[0m sorted_sources \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(sources, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: (x[\u001b[39m0\u001b[39m], \u001b[39mint\u001b[39m(x[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m])))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "# Define Sources\n",
    "sources = [(os.path.basename(doc.metadata[\"source\"]), f\"page: {doc.metadata['page']}\") for doc in result['source_documents']]\n",
    "\n",
    "# Sort sources by filename and page number\n",
    "sorted_sources = sorted(sources, key=lambda x: (x[0], int(x[1].split(\" \")[1])))\n",
    "\n",
    "# Print Answer and Sources\n",
    "print(\"\\n--------------------------------------------------------------------\")\n",
    "print(colored(\"Answer:\", \"green\"))\n",
    "print(\"--------------------------------------------------------------------\\n\")\n",
    "print(textwrap.fill(result['result'], width=80))\n",
    "print(\"\\n--------------------------------------------------------------------\")\n",
    "print(colored(\"Sources:\", \"green\"))\n",
    "print(\"--------------------------------------------------------------------\\n\")\n",
    "for source in sorted_sources:\n",
    "    print(source)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ```qa_all_at_once_iterated```\n",
    "Searches for the answer through all documents. Can also take the chat history into consideration. Does iterated prompts to get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_all_at_once_iterated(folder_path, chain_type, chunk_size, query, k, num_iterations, own_knowledge = False, show_pages=False):\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Read-in and split the documents\n",
    "    \"\"\"\n",
    "    all_pages = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        if file_name.endswith('.pdf'):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif file_name.endswith('.csv'):\n",
    "            loader = CSVLoader(file_path)\n",
    "        elif file_name.endswith('.docx'):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        elif file_name.endswith('.md'):\n",
    "            loader = UnstructuredMarkdownLoader(file_path)\n",
    "        else:\n",
    "            continue  # Skip files with other extensions\n",
    "\n",
    "        file = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_size/2)\n",
    "        pages = text_splitter.split_documents(file)\n",
    "        all_pages.extend(pages)\n",
    "\n",
    "    if show_pages:\n",
    "        print(len(all_pages))\n",
    "        for page in all_pages:\n",
    "            print(page)\n",
    "\n",
    "    \"\"\"\n",
    "    Vectorstores\n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    db = FAISS.from_documents(all_pages, embeddings)\n",
    "    # FAISS vectorstores can also be merged and saved to disk\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Prompts\n",
    "    \"\"\"\n",
    "\n",
    "    # Define Chain\n",
    "    if own_knowledge:\n",
    "        prompt_template = \"\"\"Use the following pieces of chat history and context to answer the question at the end. \\\n",
    "            If the answer does not become clear from the context, you can also use your own knowledge. \\\n",
    "            If you use your own knowledge, please indicate this clearly in your answer. \\\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        {question}\n",
    "        Helpful answer:\"\"\"\n",
    "\n",
    "    if not own_knowledge:\n",
    "\n",
    "        prompt_template = \"\"\"Use the following pieces of chat history and context to answer the question at the end. \\\n",
    "            Do NOT use your own knowledge and give the best possible answer from the context.\\\n",
    "        \n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        {question}\n",
    "        Helpful answer:\"\"\"\n",
    "\n",
    "\n",
    "    PROMPT = PromptTemplate(\n",
    "        template=prompt_template, input_variables=[\"context\",\"question\"]\n",
    "    )\n",
    "\n",
    "    chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Chains\n",
    "    \"\"\"\n",
    "    # Define summary chain\n",
    "    text_splitter = CharacterTextSplitter()\n",
    "    qa_condense = load_summarize_chain(llm=OpenAI(temperature=0), chain_type=\"stuff\")\n",
    "    \n",
    "    extended_answers = []\n",
    "    unique_sources = set()\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        # QA chain that is adaptable\n",
    "        # Amount of returned documents k-i -> makes it adaptable. Otherwise, it would always return k documents and the output would be the same.\n",
    "        retriever = db.as_retriever(\n",
    "            search_type=\"similarity\", search_kwargs={\"k\": k-i})\n",
    "\n",
    "        # Define retrieval chain\n",
    "        qa = RetrievalQA.from_chain_type(\n",
    "            llm=OpenAI(temperature=0),\n",
    "            chain_type=chain_type,\n",
    "            retriever=retriever,\n",
    "            return_source_documents=True,\n",
    "            chain_type_kwargs=chain_type_kwargs\n",
    "        )\n",
    "\n",
    "        # Run Chain with parameters\n",
    "        result = qa(query)\n",
    "\n",
    "        # Get Sources\n",
    "        sources = [(doc.page_content, os.path.basename(doc.metadata[\"source\"]), f\"page: {doc.metadata['page']}\") for doc in\n",
    "                result['source_documents']]\n",
    "\n",
    "        # Append result to extended_answers\n",
    "        extended_answers.append(result['result'])\n",
    "\n",
    "        # Add sources to the unique_sources set\n",
    "        unique_sources.update(sources)\n",
    "\n",
    "\n",
    "    # Combine extended_answers\n",
    "    combined_result = ' '.join(extended_answers)\n",
    "\n",
    "    # Run the qa function on the combined_result (summary)\n",
    "    texts = text_splitter.split_text(combined_result)\n",
    "    docs = [Document(page_content=t) for t in texts[:3]]\n",
    "    \n",
    "    condensed_result = str(qa_condense.run(docs))\n",
    "\n",
    "    # Combine unique_sources\n",
    "    combined_sources = {tuple([source[1], source[2]]): source[0] for source in unique_sources}\n",
    "\n",
    "    \n",
    "    return combined_result, condensed_result, combined_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the chat history: \n",
      " {} \n",
      "And this is the current question: \n",
      " What is a LSTM model?.\n"
     ]
    }
   ],
   "source": [
    "# Define the Query\n",
    "query = \"What is a LSTM model?\"\n",
    "\n",
    "# Update the query with the Chat History\n",
    "query_with_context = f\"This is the chat history: \\n {str(chat_history)} \\nAnd this is the current question: \\n {query}.\"\n",
    "print(query_with_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Results\n",
    "In case you do not want the chat history to be part of the prompt, change ```query=query```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------\n",
      "\u001b[32mCombined Answer:\u001b[0m\n",
      "--------------------------------------------------------------------\n",
      "\n",
      " A LSTM (Long Short Term Memory) model is a variation of a recurrent neural\n",
      "network which can be trained using an optimization algorithm like gradient\n",
      "descent on a set of training sequences. It was first introduced by Hochreiter\n",
      "and Schmidhuber in 1997 as an updated version of RNN for addressing the problems\n",
      "like vanishing gradient and later was simplified or refined. LSTM is capable of\n",
      "learning long term dependencies and is capable of remembering for a long period\n",
      "of time using a memory unit.  A LSTM (Long Short Term Memory) model is a\n",
      "variation of a recurrent neural network which can be trained using an\n",
      "optimization algorithm like gradient descent on a set of training sequences. It\n",
      "was first introduced by Hochreiter and Schmidhuber in 1997 as an updated version\n",
      "of RNN for addressing the problems like vanishing gradient and later were\n",
      "simplified or re-engineered for better performance in time series prediction.  A\n",
      "LSTM (Long Short Term Memory) model is a variation of a recurrent neural network\n",
      "which can be trained using an optimization algorithm like gradient descent on a\n",
      "set of training sequences. It was first introduced by Hochreiter and Schmidhuber\n",
      "in 1997 as an updated version of RNN for addressing the problems like vanishing\n",
      "gradient and later were simplified or re-introduced in time series prediction.\n",
      "A Long Short Term Memory (LSTM) model is a variation of a recurrent neural\n",
      "network which can be trained using an optimization algorithm like gradient\n",
      "descent on a set of training sequences. It was first introduced by Hochreiter\n",
      "and Schmidhuber in 1997 as an updated version of RNN for addressing problems\n",
      "like vanishing gradient and later was simplified or re-introduced in time series\n",
      "prediction.\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\u001b[32mCondensed Answer:\u001b[0m\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "  A Long Short Term Memory (LSTM) model is a variation of a recurrent neural\n",
      "network which was first introduced by Hochreiter and Schmidhuber in 1997 to\n",
      "address problems like vanishing gradient. It can be trained using an\n",
      "optimization algorithm like gradient descent on a set of training sequences and\n",
      "is capable of learning long term dependencies and remembering for a long period\n",
      "of time. It has been refined and re-introduced in time series prediction.\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\u001b[32mCombined Sources:\u001b[0m\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "('file1.pdf', 'page: 1')\n",
      "\n",
      "('file1.pdf', 'page: 9')\n",
      "\n",
      "('file1.pdf', 'page: 5')\n",
      "\n",
      "('file1.pdf', 'page: 11')\n",
      "\n",
      "('file1.pdf', 'page: 7')\n",
      "\n",
      "('file1.pdf', 'page: 0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Results\n",
    "combined_result, condensed_result, combined_sources = qa_all_at_once_iterated(folder_path=folder_path, \n",
    "            chain_type=\"stuff\",\n",
    "            chunk_size=500, \n",
    "            query=query_with_context, \n",
    "            k=8, \n",
    "            num_iterations=4,\n",
    "            own_knowledge = True, \n",
    "            show_pages=False)\n",
    "\n",
    "# Append Queries and Answers to Chat History\n",
    "chat_history[query] = condensed_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------\n",
      "\u001b[32mCombined Answer:\u001b[0m\n",
      "--------------------------------------------------------------------\n",
      "\n",
      " A LSTM (Long Short Term Memory) model is a variation of a recurrent neural\n",
      "network which can be trained using an optimization algorithm like gradient\n",
      "descent on a set of training sequences. It was first introduced by Hochreiter\n",
      "and Schmidhuber in 1997 as an updated version of RNN for addressing the problems\n",
      "like vanishing gradient and later was simplified or refined. LSTM is capable of\n",
      "learning long term dependencies and is capable of remembering for a long period\n",
      "of time using a memory unit.  A LSTM (Long Short Term Memory) model is a\n",
      "variation of a recurrent neural network which can be trained using an\n",
      "optimization algorithm like gradient descent on a set of training sequences. It\n",
      "was first introduced by Hochreiter and Schmidhuber in 1997 as an updated version\n",
      "of RNN for addressing the problems like vanishing gradient and later were\n",
      "simplified or re-engineered for better performance in time series prediction.  A\n",
      "LSTM (Long Short Term Memory) model is a variation of a recurrent neural network\n",
      "which can be trained using an optimization algorithm like gradient descent on a\n",
      "set of training sequences. It was first introduced by Hochreiter and Schmidhuber\n",
      "in 1997 as an updated version of RNN for addressing the problems like vanishing\n",
      "gradient and later were simplified or re-introduced in time series prediction.\n",
      "A Long Short Term Memory (LSTM) model is a variation of a recurrent neural\n",
      "network which can be trained using an optimization algorithm like gradient\n",
      "descent on a set of training sequences. It was first introduced by Hochreiter\n",
      "and Schmidhuber in 1997 as an updated version of RNN for addressing problems\n",
      "like vanishing gradient and later was simplified or re-introduced in time series\n",
      "prediction.\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\u001b[32mCondensed Answer:\u001b[0m\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "  A Long Short Term Memory (LSTM) model is a variation of a recurrent neural\n",
      "network which was first introduced by Hochreiter and Schmidhuber in 1997 to\n",
      "address problems like vanishing gradient. It can be trained using an\n",
      "optimization algorithm like gradient descent on a set of training sequences and\n",
      "is capable of learning long term dependencies and remembering for a long period\n",
      "of time. It has been refined and re-introduced in time series prediction.\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\u001b[32mCombined Sources:\u001b[0m\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "('file1.pdf', 'page: 0')\n",
      "nature of this unsettled  market. This paper presents  a new model that combines  two powerful  neural networks  \n",
      "used for time series prediction:  Gated Recurrent  Unit (GRU) and Long Short Term Memory  (LSTM),  for predicting  \n",
      "the future closing prices of FOREX currencies.  The ﬁrst layer of our proposed  model is the GRU layer with 20 \n",
      "hidden neurons  and the second layer is the LSTM layer with 256 hidden neurons.  We have applied our model on\n",
      "\n",
      "('file1.pdf', 'page: 1')\n",
      "The main aim of this research  is to demonstrate  the combined  power \n",
      "of two of the most powerful  time-series  analyzers:  Gated Recurrent  Unit \n",
      "(GRU) and Long Short Term Memory  (LSTM),  to predict FOREX cur- \n",
      "rency price. For this purpose,  we have developed  a hybrid model that \n",
      "has a GRU at the front layer and LSTM at the back. We applied  our \n",
      "proposed  model to predict the closing price of four major FOREX cur- \n",
      "rency pairs: EUR/USD,  GBP/USD,  USD/CAD,  and USD/CHF.  As a proof\n",
      "\n",
      "('file1.pdf', 'page: 5')\n",
      "will be close to 1, allowing  the majority  of the past information  to be \n",
      "kept. \n",
      "3.2. Long short term memory  \n",
      "An LSTM is another  variation  of recurrent  neural network  which can \n",
      "be trained  using an optimization  algorithm  like gradient  descent  on a set \n",
      "of the training  sequence.  LSTM was ﬁrst introduced  by Hochreiter  and \n",
      "Schmidhuber  [63] in 1997 as an updated  version  of RNN for addressing  \n",
      "the problems  like vanishing  gradient  and later were simpliﬁed  or re-\n",
      "\n",
      "('file1.pdf', 'page: 7')\n",
      "tains LSTM with 256 hidden neurons.  The third layer and fourth layers \n",
      "are dense layers with 64 and 1 hidden neurons  respectively.  We have \n",
      "trained  this model using the 10 minutes  and 30 minutes  interval  data \n",
      "which we have processed  from the original  1-minute  interval  data. The\n",
      "\n",
      "('file1.pdf', 'page: 9')\n",
      "individual  models and its not possible  to understand  the diﬀerence  with- \n",
      "out proper comparison.  Another  reason for choosing  these two models is \n",
      "their performance,  which is better than other deep learning  approaches  \n",
      "[16] in time series prediction.  Both of the GRU and LSTM model were \n",
      "trained  using the same data- sets, same hidden layer formation  and was \n",
      "run 100 times each as our proposed  model. Moreover,  this proposed\n",
      "\n",
      "('file1.pdf', 'page: 11')\n",
      "GRU-LSTM  model against  a standalone  GRU model, a standalone  LSTM \n",
      "model, and a simple statistical  model where we have used simple mov- \n",
      "ing average  (SMA) of previous  20-days  closing price. Moving  average  is \n",
      "used for ﬁltering  out the noise and smoothing  the price trend. We have \n",
      "considered  a 20-days  moving  average  for analyzing  the performance  as \n",
      "a 20-days  moving  average  is proven to provide  the best result [70] .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print Answer and Sources\n",
    "print(\"\\n--------------------------------------------------------------------\")\n",
    "print(colored(\"Combined Answer:\", \"green\"))\n",
    "print(\"--------------------------------------------------------------------\\n\")\n",
    "print(textwrap.fill(combined_result, width=80))\n",
    "print(\"\\n--------------------------------------------------------------------\")\n",
    "print(colored(\"Condensed Answer:\", \"green\"))\n",
    "print(\"--------------------------------------------------------------------\\n\")\n",
    "print(textwrap.fill(condensed_result, width=80))\n",
    "print(\"\\n--------------------------------------------------------------------\")\n",
    "print(colored(\"Combined Sources:\", \"green\"))\n",
    "print(\"--------------------------------------------------------------------\\n\")\n",
    "\n",
    "# Print Sources and Sort them first\n",
    "for source_key, source_element in sorted(combined_sources.items(), key=lambda x: (x[0][0], int(x[0][1].split(\" \")[1]))):\n",
    "    print(f'{source_key}\\n{source_element}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
