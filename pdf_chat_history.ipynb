{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain openai chromadb pypdf tiktoken faiss-cpu Flask unstructured Cython pdfminer.six termcolor prettytable tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cesar\\OneDrive\\Desktop\\Code\\langchain-pdf-bot\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Document loaders\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "# Splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "# Embeddings and models\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import FAISS, Chroma\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "# Chains\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "# Utils\n",
    "import os\n",
    "from termcolor import colored\n",
    "import textwrap\n",
    "from prettytable import PrettyTable\n",
    "import ast\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Import API Key\n",
    "from apikey import API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folder Path Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r\"C:\\Users\\cesar\\OneDrive\\Desktop\\test2\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ```qa_single_file```\n",
    "This iterates over each file seperately, asking each one the same question. Good for literature overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_single_file(folder_path, chain_type, chunk_size, query, k, own_knowledge = False, show_pages=False):\n",
    "\n",
    "    # Define output table.\n",
    "    tables = {}\n",
    "\n",
    "    # Wraptext function for prettytable\n",
    "    def wrap_text(text, width=40):\n",
    "        return \"\\n\".join(textwrap.wrap(text, width=width))\n",
    "\n",
    "    \"\"\"\n",
    "    Read-in and split the documents\n",
    "    \"\"\"\n",
    "    # Loop over all files in folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        # Clear all_pages\n",
    "        all_pages = []\n",
    "\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        if file_name.endswith('.pdf'):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif file_name.endswith('.csv'):\n",
    "            loader = CSVLoader(file_path)\n",
    "        elif file_name.endswith('.docx'):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        elif file_name.endswith('.md'):\n",
    "            loader = UnstructuredMarkdownLoader(file_path)\n",
    "        else:\n",
    "            continue  # Skip files with other extensions\n",
    "\n",
    "        file = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_size/2)\n",
    "        pages = text_splitter.split_documents(file)\n",
    "        all_pages.extend(pages)\n",
    "\n",
    "        if show_pages:\n",
    "            print(len(all_pages))\n",
    "            for page in all_pages:\n",
    "                print(page)\n",
    "\n",
    "        \"\"\"\n",
    "        Vectorstores\n",
    "        \"\"\"\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "\n",
    "        db = FAISS.from_documents(all_pages, embeddings)\n",
    "        # FAISS vectorstores can also be merged and saved to disk\n",
    "\n",
    "        \"\"\"\n",
    "        Retriever\n",
    "        \"\"\"\n",
    "        # Amount of returned documents k\n",
    "        retriever = db.as_retriever(\n",
    "            search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "\n",
    "        \"\"\"\n",
    "        Chains\n",
    "        \"\"\"\n",
    "\n",
    "        # Define Chain\n",
    "        if own_knowledge:\n",
    "            prompt_template = \"\"\"Use the following pieces of context to find an answer to all the keys given in the question. \\\n",
    "                Give your answer in the form of a dictionary with the keys given in the question. \\\n",
    "                If the answer does not become clear from the context, you can also use your own knowledge. \\\n",
    "                If you use your own knowledge, please indicate this clearly in your answer. \\\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            {question}\n",
    "            Helpful answer:\"\"\"\n",
    "\n",
    "        if not own_knowledge:\n",
    "\n",
    "            prompt_template = \"\"\"Use the following pieces of context to find an answer to all the keys given in the question. \\\n",
    "                Give your answer in the form of a dictionary with the keys given in the question. \\\n",
    "                Do NOT use your own knowledge and give the best possible answer from the context.\\\n",
    "            \n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            {question}\n",
    "            Helpful answer:\"\"\"\n",
    "\n",
    "\n",
    "        PROMPT = PromptTemplate(\n",
    "            template=prompt_template, input_variables=[\"context\",\"question\"]\n",
    "        )\n",
    "\n",
    "        chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "        # Define Chain\n",
    "        qa = RetrievalQA.from_chain_type(\n",
    "            llm=OpenAI(temperature=0),\n",
    "            chain_type=chain_type,\n",
    "            retriever=retriever,\n",
    "            return_source_documents=True,\n",
    "            chain_type_kwargs=chain_type_kwargs\n",
    "        )\n",
    "        \n",
    "\n",
    "        # Run Chain with parameters\n",
    "        result = qa(query)\n",
    "\n",
    "        # Convert string representation of dictionary to an actual dictionary\n",
    "        result_dict = ast.literal_eval(result['result'])\n",
    "\n",
    "        # Get Sources\n",
    "        sources = [(os.path.basename(doc.metadata[\"source\"]), f\"page: {doc.metadata['page']}\") for doc in result['source_documents']]\n",
    "\n",
    "        # Append result to output tables\n",
    "        table_key = (file_name, tuple(sources))\n",
    "        if table_key not in tables:\n",
    "            table_columns = [\"Filename\", \"Sources\"] + list(result_dict.keys())\n",
    "            tables[table_key] = PrettyTable(table_columns)\n",
    "        table_row = [wrap_text(table_key[0]), wrap_text(', '.join([f'{source[0]} {source[1]}' for source in table_key[1]]))] + [wrap_text(str(value)) for value in result_dict.values()]\n",
    "        tables[table_key].add_row(table_row)\n",
    "\n",
    "    # Return output tables\n",
    "    return tables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"model specification, model estimation, model evaluation, model deployment, benchmark models\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Results\n",
    "Use smaller chunk sizes to catch more different part in one prompt. Use at least as many chunks (k) as there are keys in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFilename: file1.pdf\u001b[0m\n",
      "+-----------+----------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "|  Filename |                Sources                 |          model specification          |             model estimation             |             model evaluation             |             model deployment             |             benchmark models            |\n",
      "+-----------+----------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "| file1.pdf | file1.pdf page: 8, file1.pdf page: 13, |    Support vector regression (SVR),   | The weights that were generated by these | Validation is an important step that is  | Based on the saved weighted values, the  |  They tested their model against other  |\n",
      "|           | file1.pdf page: 2, file1.pdf page: 1,  | multiple linear regression (MLR), CRT | four algorithms were used as the inputs  |   used to check the performance of the   | future predictions for 10 minutes and 30 | models supported by ELM, NN, and FLANN. |\n",
      "|           |           file1.pdf page: 1            |   regression tree, and partial least  |     of the Cuckoo search algorithm.      | system by comparing the actual data with |    minutes are done and the system’s     |   They found that between ELM, NN, and  |\n",
      "|           |                                        | squares (PLS) regression methods were |                                          |  predicted data. Here we have used MSE   |         performance is measured.         |   FLANN, ELM shows the most effective   |\n",
      "|           |                                        |      used to train their dataset.     |                                          |  (Mean Squared Error), RMSE (Root Mean   |                                          |              optimization.              |\n",
      "|           |                                        |                                       |                                          |    Square Error), MAPE (Mean Absolute    |                                          |                                         |\n",
      "|           |                                        |                                       |                                          |  Percentage Error), MAE (Mean Absolute   |                                          |                                         |\n",
      "|           |                                        |                                       |                                          |      Error), ARV (Absolute Relative      |                                          |                                         |\n",
      "|           |                                        |                                       |                                          |         Variance), and Theils U.         |                                          |                                         |\n",
      "+-----------+----------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "\n",
      "\u001b[32mFilename: file2.pdf\u001b[0m\n",
      "+-----------+----------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "|  Filename |                Sources                 |          model specification          |             model estimation             |             model evaluation             |             model deployment             |             benchmark models            |\n",
      "+-----------+----------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "| file2.pdf | file2.pdf page: 8, file2.pdf page: 13, |    Support vector regression (SVR),   | The weights that were generated by these | Validation is an important step that is  | Based on the saved weighted values, the  |  They tested their model against other  |\n",
      "|           | file2.pdf page: 2, file2.pdf page: 1,  | multiple linear regression (MLR), CRT | four algorithms were used as the inputs  |   used to check the performance of the   | future predictions for 10 minutes and 30 | models supported by ELM, NN, and FLANN. |\n",
      "|           |           file2.pdf page: 1            |   regression tree, and partial least  |     of the Cuckoo search algorithm.      | system by comparing the actual data with |    minutes are done and the system’s     |   They found that between ELM, NN, and  |\n",
      "|           |                                        | squares (PLS) regression methods were |                                          |  predicted data. Here we have used MSE   |         performance is measured.         |   FLANN, ELM shows the most effective   |\n",
      "|           |                                        |      used to train their dataset.     |                                          |  (Mean Squared Error), RMSE (Root Mean   |                                          |              optimization.              |\n",
      "|           |                                        |                                       |                                          |    Square Error), MAPE (Mean Absolute    |                                          |                                         |\n",
      "|           |                                        |                                       |                                          |  Percentage Error), MAE (Mean Absolute   |                                          |                                         |\n",
      "|           |                                        |                                       |                                          |      Error), ARV (Absolute Relative      |                                          |                                         |\n",
      "|           |                                        |                                       |                                          |         Variance), and Theils U.         |                                          |                                         |\n",
      "+-----------+----------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate Output Table\n",
    "output_table = qa_single_file(folder_path=folder_path, \n",
    "            chain_type=\"stuff\",\n",
    "            chunk_size=500, \n",
    "            query=query, \n",
    "            k=5, \n",
    "            own_knowledge = True, \n",
    "            show_pages=False)\n",
    "\n",
    "# Print Output Table\n",
    "for table_key, table_value in output_table.items():\n",
    "    print(colored(f\"Filename: {table_key[0]}\", \"green\"))\n",
    "    print(table_value)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ```qa_single_file_iterated```\n",
    "This iterates over each file **and key** seperately to be even more accurate with the single answers, asking each one the same question. Good for literature overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_single_file_iterated(folder_path, chain_type, chunk_size, queries, k, own_knowledge = False, show_pages=False):\n",
    "\n",
    "    # Define output table.\n",
    "    tables = {}\n",
    "\n",
    "    # Wraptext function for prettytable\n",
    "    def wrap_text(text, width=80):\n",
    "        return textwrap.fill(text, width=width)\n",
    "\n",
    "    \"\"\"\n",
    "    Read-in and split the documents\n",
    "    \"\"\"\n",
    "    # Loop over all files in folder\n",
    "    for file_name in tqdm(os.listdir(folder_path), desc=\"Processing files\",  colour=\"green\", leave=False):\n",
    "        # Clear all_pages\n",
    "        all_pages = []\n",
    "\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        if file_name.endswith('.pdf'):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif file_name.endswith('.csv'):\n",
    "            loader = CSVLoader(file_path)\n",
    "        elif file_name.endswith('.docx'):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        elif file_name.endswith('.md'):\n",
    "            loader = UnstructuredMarkdownLoader(file_path)\n",
    "        else:\n",
    "            continue  # Skip files with other extensions\n",
    "\n",
    "        file = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_size/2)\n",
    "        pages = text_splitter.split_documents(file)\n",
    "        all_pages.extend(pages)\n",
    "\n",
    "        if show_pages:\n",
    "            print(len(all_pages))\n",
    "            for page in all_pages:\n",
    "                print(page)\n",
    "\n",
    "        \"\"\"\n",
    "        Vectorstores\n",
    "        \"\"\"\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "\n",
    "        db = FAISS.from_documents(all_pages, embeddings)\n",
    "        # FAISS vectorstores can also be merged and saved to disk\n",
    "\n",
    "        \"\"\"\n",
    "        Retriever\n",
    "        \"\"\"\n",
    "        # Amount of returned documents k\n",
    "        retriever = db.as_retriever(\n",
    "            search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "\n",
    "        \"\"\"\n",
    "        Chains\n",
    "        \"\"\"\n",
    "\n",
    "        # Define Chain\n",
    "        if own_knowledge:\n",
    "            prompt_template = \"\"\"Use the following pieces of context to find an answer to the given question. \\\n",
    "                If the answer does not become clear from the context, you can also use your own knowledge. \\\n",
    "                If you use your own knowledge, please indicate this clearly in your answer. \\\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            Question:\n",
    "            Based on the context, how does the context define and apply: {question}?\n",
    "            Helpful answer:\"\"\"\n",
    "\n",
    "        if not own_knowledge:\n",
    "\n",
    "            prompt_template = \"\"\"Use the following pieces of context to find an answer to the given question. \\\n",
    "                Do NOT use your own knowledge and give the best possible answer from the context.\\\n",
    "            \n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            Question:\n",
    "            Based on the context, how does the context define and apply: {question}?\n",
    "            Helpful answer:\"\"\"\n",
    "\n",
    "\n",
    "        PROMPT = PromptTemplate(\n",
    "            template=prompt_template, input_variables=[\"context\",\"question\"]\n",
    "        )\n",
    "\n",
    "        chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "        # Define Chain\n",
    "        qa = RetrievalQA.from_chain_type(\n",
    "            llm=OpenAI(temperature=0),\n",
    "            chain_type=chain_type,\n",
    "            retriever=retriever,\n",
    "            return_source_documents=True,\n",
    "            chain_type_kwargs=chain_type_kwargs\n",
    "        )\n",
    "        \n",
    "\n",
    "        # Iterate over each query\n",
    "        for query in queries:\n",
    "            # Run Chain with parameters\n",
    "            result = qa(query)\n",
    "\n",
    "            # Get Sources\n",
    "            sources = [({doc.page_content}, os.path.basename(doc.metadata[\"source\"]), f\"page: {doc.metadata['page']}\") for doc in\n",
    "                    result['source_documents']]\n",
    "\n",
    "            # Append result to output tables\n",
    "            table_key = file_name\n",
    "            if table_key not in tables:\n",
    "                table_columns = [query]\n",
    "                tables[table_key] = PrettyTable(table_columns)\n",
    "            else:\n",
    "                if query not in tables[table_key].field_names:\n",
    "                    empty_column = [\"\"] * len(tables[table_key]._rows)\n",
    "                    tables[table_key].add_column(query, empty_column)\n",
    "\n",
    "            # Add sources to the result value\n",
    "            result_with_sources = colored(wrap_text(str(result['result'])), \"green\") + \"\\n Sources:\" + wrap_text('\\n'.join([f'{source[0]} {source[1]} {source[2]}' for source in sources]))\n",
    "\n",
    "\n",
    "            # Update the last row of the table or add a new row\n",
    "            if len(tables[table_key]._rows) > 0:\n",
    "                last_row_index = len(tables[table_key]._rows) - 1\n",
    "                tables[table_key]._rows[last_row_index][tables[table_key].field_names.index(query)] = wrap_text(result_with_sources)\n",
    "            else:\n",
    "                new_row = [\"\"] * len(tables[table_key].field_names)\n",
    "                new_row[tables[table_key].field_names.index(query)] = wrap_text(result_with_sources)\n",
    "                tables[table_key].add_row(new_row)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Return output tables\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"model specification\", \"model estimation\", \"model evaluation\", \"model deployment\", \"benchmark models\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Results\n",
    "Use smaller chunk sizes to catch more different part in one prompt. Use at least as many chunks (k) as there are keys in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFilename: file1.pdf\u001b[0m\n",
      "+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+\n",
      "|                               model specification                                |                                 model estimation                                 |                                 model evaluation                                 |                                 model deployment                                 |                                 benchmark models                                 |\n",
      "+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+\n",
      "|    \u001b[32m             The context defines model specification as the combination of    |    \u001b[32m Model estimation is the process of using regression techniques to compare    |     \u001b[32m Model evaluation is defined as the process of comparing the actual data     |     \u001b[32m Model deployment is the process of making a model available for use in      |   \u001b[32m Benchmark models are used in the context to compare the performance of the    |\n",
      "|     regression techniques with the cuckoo search algorithm, inspired by the      |    actual data with predicted data in order to measure the performance of the    |    with predicted data using performance matrices such as MSE, RMSE, MAE, and    |    production. In the context, model deployment is discussed in terms of the     |  proposed hybrid model against a simple statistical model that uses the simple   |\n",
      "| autoregressive moving average (ARMA) model, to predict the exchange market. The  |    system. This is done by calculating the MSE, RMSE, MAE, and R-squared (R2)    |  R-squared score to measure the performance of the system. The context applies   |   evaluation of the system's performance by comparing the actual data with the   |   moving average of the previous 20-days closing price. The performance of the   |\n",
      "|    model is validated against 14886 samples for the 10-minute model and 3723     |    values.\u001b[0m  Sources:{'the future predictions  for 10 minutes  and 30 minutes     |  model evaluation by comparing the proposed models against a standalone GRU, a   |  predicted data. This is done by measuring the performance of the system using   | proposed model is compared to the standalone LSTM model, a standalone GRU model, |\n",
      "|   samples for the 30-minute model, and is trained using the rest of the data.\u001b[0m    | are done and the \\nsystem’s  performance  is measured.  \\n4.4. Model validation  |       standalone LSTM, and a statistical model based on the moving average       |  metrics such as MSE, RMSE, MAE, and R-squared value. Additionally, the context  |   and the simple moving average (SMA) based statistical model in terms of MSE,   |\n",
      "|    Sources:{'model, these values are 0.00084,  0.02895,  0.01448  and 0.93690    | \\nValidation  is an important  step that is used to check the performance  \\nof  |   technique.\u001b[0m  Sources:{'the future predictions  for 10 minutes  and 30 minutes   |  discusses the use of hybrid models, which combine multiple models, to improve   |   RMSE, MAE, and 𝑅2 scores. The comparison of the models is used to determine    |\n",
      "| respec- \\ntively. The actual vs predicted  value curves are provided  in Figs. 7 | the system by comparing  the actual data with predicted  data. Here we have used | are done and the \\nsystem’s  performance  is measured.  \\n4.4. Model validation  |    the accuracy and reduce uncertainty.\u001b[0m  Sources:{'M.S. Islam and E. Hossain     |    which model is the least risky and most reliable.\u001b[0m  Sources:{'our proposed     |\n",
      "|    and \\n8 . \\nThe x-axis indicates  the number  of test samples  (14871  for    |  MSE (Mean Squared  Error), RMSE (Root Mean Square Error), \\nMAE (Mean Absolute  | \\nValidation  is an important  step that is used to check the performance  \\nof  |  Soft Computing  Letters 3 (2021) 100009 \\nFig. 1. Simple architecture  of our   | hybrid model against  a simple statistical  model that uses \\nthe simple moving  |\n",
      "|  10-mins \\nmodel and 37224 samples  for 30-mins  model) that have been used for  |  Error), and R-squared  ( 𝑅 2 ) value for measuring  the \\nperformance  of our   | the system by comparing  the actual data with predicted  data. Here we have used |  proposed  pipeline.  \\nUSDINR.  They tested their model against  other models   |   average  of the previous  20-days  closing price. Al- \\nthough,  this model    |\n",
      "| \\nprediction.  The actual closing values of the currency  pairs are marked  \\nby | system. Among  them in MSE and RMSE, the error'} file1.pdf page: 8 {'M.S. Islam  |  MSE (Mean Squared  Error), RMSE (Root Mean Square Error), \\nMAE (Mean Absolute  |    supported  by \\nELM, NN, and FLANN.  They found that between  ELM, NN, and    | produces  less error for EUR/USD  and USD/CHF  in \\n30-mins  timeframe,  but it  |\n",
      "| yellow color and model predicted  closing values are marked  by blue'} file1.pdf |     and E. Hossain Soft Computing  Letters 3 (2021) 100009 \\nFig. 1. Simple      |  Error), and R-squared  ( 𝑅 2 ) value for measuring  the \\nperformance  of our   |   FLANN,  \\nELM shows the most eﬀective  optimization. Consistent  with their    |  has a very high risk associated  with it. In \\nterms of risk associated  with   |\n",
      "| page: 10 {'system architecture  of our proposed  system.  \\n4.1. Data collection |   architecture of our proposed  pipeline.  \\nUSDINR.  They tested their model    |  system. Among  them in MSE and RMSE, the error'} file1.pdf page: 8 {'than the   |  eval- \\nuation data, for MAPE evaluation  ELM DE provides rock bottom  error.   |    the return, the proposed  model maintains \\nits superiority  among all the    |\n",
      "|     \\nThe dataset was collected  from Histdata  [65] website.  Data was col-     |    against  other models supported  by \\nELM, NN, and FLANN.  They found that    |      actual time. Also, we have compared  our proposed  models \\nagainst  a      |  \\nFor MAE, ARV, and Theils U models ELM TLBO, ELM PSO and ELM Jaya'} file1.pdf  |  models for both timeframes.  Although  the'} file1.pdf page: 14 {'model, these  |\n",
      "|     \\nlected for four major currency  pairs: EUR/USD  [66] , GBP/USD  [67] ,     |    between  ELM, NN, and FLANN,  \\nELM shows the most eﬀective  optimization.    | standalone  GRU, a standalone  LSTM, and a statistical  model \\nthat is based on |  page: 2 {'the future predictions  for 10 minutes  and 30 minutes  are done and  |    values are 0.00084,  0.02895,  0.01448  and 0.93690  respec- \\ntively. The    |\n",
      "|    \\nUSD/CAD  [68] , and USD/CHF  [69] . We have collected  two years of his-    | Consistent  with their eval- \\nuation data, for MAPE evaluation  ELM DE provides |    the moving average  technique.  \\n5.1. Performance  evaluation  \\nFor each    | the \\nsystem’s  performance  is measured.  \\n4.4. Model validation  \\nValidation | actual vs predicted  value curves are provided in Figs. 7 and \\n8 . \\nThe x-axis |\n",
      "| \\ntorical time series data from 1st January,  2017 to 31st December,  2018 \\nfor |  rock bottom  error. \\nFor MAE, ARV, and Theils U models ELM TLBO, ELM PSO and   | currency  pair, our model was trained  using the 20-256-64  \\nformation  of the  | is an important  step that is used to check the performance  \\nof the system by  |  indicates  the number  of test samples  (14871 for 10-mins  \\nmodel and 37224   |\n",
      "|     our 10 minutes  prediction  model and from 1st January,  2019 to 30th'}      |    ELM Jaya'} file1.pdf page: 2 {'model, these values are 0.00084,  0.02895,     | hidden layers and was run for 100 times. The predic- \\ntion was then done on the |   comparing  the actual data with predicted  data. Here we have used MSE (Mean   |  samples  for 30-mins  model) that have been used for \\nprediction.  The actual  |\n",
      "|  file1.pdf page: 7 {'exchange  market prediction.  A hybrid model based on the   | 0.01448  and 0.93690 respec- \\ntively. The actual vs predicted  value curves are | 20% of the total data. Then the performance'} file1.pdf page: 9 {'ELM shows the  |  Squared  Error), RMSE (Root Mean Square Error), \\nMAE (Mean Absolute  Error),   |   closing values of the currency  pairs are marked \\nby yellow color and model   |\n",
      "|    regression  \\ntechnique  was developed  by Said, Omar, and Aziz who used a    |    provided  in Figs. 7 and \\n8 . \\nThe x-axis indicates  the number  of test    |  most eﬀective  optimization.  Consistent  with their eval- \\nuation data, for   |  and R-squared  ( 𝑅 2 ) value for measuring  the \\nperformance  of our system.   |  predicted  closing values are marked  by blue'} file1.pdf page: 10 {'Proposed   |\n",
      "| combi- \\nnation of regression  techniques  with the cuckoo search algorithm [17] |   samples  (14871  for 10-mins  \\nmodel and 37224 samples  for 30-mins  model)   | MAPE evaluation  ELM DE provides  rock bottom  error. \\nFor MAE, ARV, and Theils |  Among  them in MSE and RMSE, the error'} file1.pdf page: 8 {'M.S. Islam and E.  |   Model 0.99205 0.93690 0.99287 0.98159 \\nLSTM 0.98358 0.92664 0.59762 0.30702   |\n",
      "|   . \\nTheir model was inspired  by the autoregressive  moving  average (ARMA)    | that have been used for \\nprediction.  The actual closing values of the currency |  U models ELM TLBO, ELM PSO and ELM Jaya \\nprovided  the most eﬀective  result   |    Hossain Soft Computing  Letters 3 (2021) 100009 \\nFig. 3. Distribution  of    |   \\nGRU 0.99052 0.68449 0.90486 0.98010 \\nSMA 0.39487 0.05839 0.01325 0.21750    |\n",
      "|    \\nmodel and they prepared  their dataset with historical  data of USD/EUR     |   pairs are marked  \\nby yellow color and model predicted  closing values are    |     respectively.  For FOREX trading  strat- \\negy optimization,  a genetic      |     diﬀerences  between  ac- \\ntual and predicted curve for EUR/USD  10-mins     | \\nand 0.21750,  respectively)  among all the models and thus have a huge \\nrisk  |\n",
      "| \\ncurrency  pair. Support  vector regression  (SVR), multiple  linear regres-'}  |   marked  by blue'} file1.pdf page: 10 {'sion (MLR), CRT regression  tree, and   |    algorithm  was employed  by Galeshchuk  and \\nMukherjee  [34] to evolve a     |    \\ntimeframe.  \\nprovided  more stability  and accuracy  in predicting  the    |  associated  with it. Table 9 and 10 show the comparison  of the mod- \\nels in   |\n",
      "| file1.pdf page: 1 {'the future predictions  for 10 minutes  and 30 minutes  are  |  partial least squares  (PLS) regres- \\nsion methods  were used to train their   |   special set of proﬁtable  trading  rules inspired'} file1.pdf page: 2 {'5.1.   | rates. The analy- \\nsis showed  that hybrid models performed  better than stand- |  terms of 𝑅 2 scores for 10-mins  and 30-mins timeframe  respec- \\ntively. Our   |\n",
      "|   done and the \\nsystem’s  performance  is measured.  \\n4.4. Model validation    |   dataset.  The weights  that were \\ngenerated  by these four algorithms  were   | Performance  evaluation  \\nFor each currency  pair, our model was trained  using |    alone  mod- \\nels. Hybrid models provided  more accuracy  and also reduced    |  proposed  model produces  higher 𝑅 2 scores than both of the'} file1.pdf page:  |\n",
      "| \\nValidation  is an important  step that is used to check the performance  \\nof  | used as the inputs of the Cuckoo  \\nsearch algorithm.  The experiment  was done  | the 20-256-64  \\nformation  of the hidden layers and was run for 100 times. The  | uncer- \\ntainty. This also motivates  us to use a combination  of GRU and LSTM'} |    13 {'exchange  market prediction.  A hybrid model based on the regression     |\n",
      "| the system by comparing  the actual data with predicted  data. Here we have used |    with two years of histori- \\ncal data. Multiple  linear regression  (MLR)     | predic- \\ntion was then done on the 20% of the total data. Then the performance  |  file1.pdf page: 3 {'system architecture  of our proposed  system.  \\n4.1. Data  |  \\ntechnique  was developed  by Said, Omar, and Aziz who used a combi- \\nnation  |\n",
      "|  MSE (Mean Squared  Error), RMSE (Root Mean Square Error), \\nMAE (Mean Absolute  |   provided  better results than \\nSVR, PLS, and CRT. Their model outperformed    | \\nwas measured  using the performance  matrices  MSE, RMSE, MAE, and \\n𝑅 2 score | collection  \\nThe dataset was collected  from Histdata  [65] website.  Data was  |   of regression  techniques  with the cuckoo search algorithm  [17] . \\nTheir    |\n",
      "|  Error), and R-squared  ( 𝑅 2 ) value for measuring  the \\nperformance  of our   |   other regression  algo-'} file1.pdf page: 1 {'color, and the model predicted   |    which compares  the diﬀerence  between  actual and predicted  \\nvalues and    |  col- \\nlected for four major currency  pairs: EUR/USD  [66] , GBP/USD  [67] ,   |  model was inspired  by the autoregressive moving  average  (ARMA)  \\nmodel and  |\n",
      "|    system.  Among  them in MSE and RMSE, the error'} file1.pdf page: 8 {'and     | closing values are marked by blue color. \\nThe y-axis indicates  the unit value  |  provided  a result between  0 and 1. We chose the perfor-'} file1.pdf page: 9   |    \\nUSD/CAD  [68] , and USD/CHF  [69] . We have collected  two years of his-    | they prepared  their dataset with historical  data of USD/EUR  \\ncurrency  pair. |\n",
      "| nonparametric  self-organising  modelling  approach, Expert Syst. Appl. 36 (10)  |  of this pair which in this case is the \\nnormalized  closing price of EUR/USD   |  {'M.S. Islam and E. Hossain Soft Computing  Letters 3 (2021) 100009 \\nFig. 1.   | \\ntorical time series data from 1st January,  2017 to 31st December,  2018 \\nfor |  Support  vector regression (SVR), multiple  linear regres-'} file1.pdf page: 1  |\n",
      "| \\n(2009) 12001–12011,  doi: 10.1016/j.eswa.2009.03.057  . \\n[4] R.D. Huang, R.W. |  currency  pair. The ﬂuctuation  in \\nthe curve indicates  the ups and downs of  |  Simple architecture  of our proposed  pipeline.  \\nUSDINR.  They tested their   |     our 10 minutes  prediction  model and from 1st January,  2019 to 30th'}      |   {'standalone  LSTM model, a standalone  GRU model and simple moving average    |\n",
      "|  Masulis, Fx spreads and dealer competition  across the 24-hour \\ntrading day,   |   the closing prices. \\nThe graphs clearly show how accurate  the predictions    | model against  other models supported  by \\nELM, NN, and FLANN.  They found that |     file1.pdf page: 7 {'vector machine  (SVM). SVM was implemented  in both      |   (SMA) based statistical  model \\nwhere the proposed  hybrid GRU-LSTM  model    |\n",
      "|   Rev. Financ. Stud. 12 (1) (1999) 61–93, doi: 10.1093/rfs/12.1.61  . \\n[5] S.   |  are: actual \\nand predicted  values almost overlap  with each other. The MSE,   |    between  ELM, NN, and FLANN,  \\nELM shows the most eﬀective  optimization.    | individual  and \\nhybrid systems  with prediction capabilities.  Thuy and Vuong  |   outperforms  all models for 10-mins timeframe  and for 30-mins  \\ntimeframe    |\n",
      "|       Masry, A. Dupuis, R. Olsen, E. Tsang, Time zone normalization  of fx       |  RMSE, \\nand MAE scores of our model for EUR/USD  10-mins  pairs are 0.00001,'}  | Consistent  with their eval- \\nuation data, for MAPE evaluation  ELM DE provides | [28] pro- \\nposed a model for foreign exchange prediction  using SVM. They used  |  provides  the best result for GBP/USD and USD/CAD  currency  pairs in terms of  |\n",
      "|          seasonality,  \\nQuant. Finance 13 (7) (2013) 1115–1123,  doi:           |  file1.pdf page: 9 {'exchange  market prediction.  A hybrid model based on the   |  rock bottom  error. \\nFor MAE, ARV, and Theils U models ELM TLBO, ELM PSO and   | \\nthe EUR/USD  currency  pair for their models implementation.  They used \\nthe  | MSE, RMSE, and MAE \\nperformance metrics.  But in terms of 𝑅 2 score, our system |\n",
      "| 10.1080/14697688.2013.773458  .'} file1.pdf page: 15 {'M.S. Islam and E. Hossain | regression \\ntechnique  was developed  by Said, Omar, and Aziz who used a combi- | ELM Jaya'} file1.pdf page: 2 {'data from January  1, 2019 to June 30, 2020 as a  | cross-validation  method  for their data-set and divided  the results \\ninto two |   outperforms  all compared models and thus proves \\nitself as the least risky   |\n",
      "|  Soft Computing  Letters 3 (2021) 100009 \\nFig. 1. Simple architecture  of our   |   \\nnation of regression  techniques  with the cuckoo search algorithm  [17] .   |   proof-of-concept.  The performance  of the model is validated  \\nusing MSE,    |   categories  positive  output and negative output.  They used ac-'} file1.pdf   |    model among all. \\n1. Introduction'} file1.pdf page: 0 {'USD/CAD  10-mins     |\n",
      "|  proposed  pipeline.  \\nUSDINR.  They tested their model against  other models   |    \\nTheir model was inspired  by the autoregressive  moving  average  (ARMA)    |  RMSE, MAE, and 𝑅 2 score. Moreover,  we have compared  the performance  of our  |  page: 1 {'see if our proposed  model improves the overall performance  and can  | performance  comparison. \\nModels MSE RMSE MAE \\nProposed  Model 0.00004 0.00597 |\n",
      "|    supported  by \\nELM, NN, and FLANN.  They found that between  ELM, NN, and    |    \\nmodel and they prepared  their dataset with historical  data of USD/EUR     |   model against a \\nstandalone  LSTM model, a standalone  GRU model and simple   |     \\noutperform  any of these algorithms  as the whole experiment  will be      |    0.00387 \\nLSTM 0.00005 0.00686 0.00464 \\nGRU 0.00041 0.02024 0.01721 \\nSMA    |\n",
      "|   FLANN,  \\nELM shows the most eﬀective  optimization. Consistent  with their    | \\ncurrency  pair. Support  vector regression  (SVR), multiple  linear regres-'}  | moving average (SMA) based statistical  model \\nwhere the proposed  hybrid GRU-  |    \\nmeaningless  if the system provides  same performance  or worse than the    |  0.00008 0.00936 0.00788 \\nTable 4 \\nUSD/CHF  10-mins  performance  comparison.  |\n",
      "|  eval- \\nuation data, for MAPE evaluation  ELM DE provides rock bottom  error.   |  file1.pdf page: 1 {'their proposed  model they found that autoregression  with  |  LSTM  model outperforms  all models for 10-mins  timeframe  and for 30-mins'}   |  \\nindividual  models and its not possible  to understand  the diﬀerence  with-  |  \\nModel MSE RMSE MAE \\nProposed  Model 0.00001 0.00362 0.00261 \\nLSTM 0.00001   |\n",
      "|  \\nFor MAE, ARV, and Theils U models ELM TLBO, ELM PSO and ELM Jaya'} file1.pdf  |  four lags also \\nreferred  to as AR(4) and time-varying  autoregression  with   |  file1.pdf page: 0 {'M.S. Islam and E. Hossain Soft Computing  Letters 3 (2021)  |   \\nout proper comparison.  Another  reason for choosing  these two models is    |   0.00385 0.00281 \\nGRU 0.00036 0.01888 0.01516 \\nSMA 0.00006 0.00825 0.00649    |\n",
      "| page: 2 {'searchers  are trying to come up with new models to predict the nature |  four lags, re- \\nferred to as TVP-AR(4)  model gives best USD-JYP  prediction   | 100009 \\nFig. 11. Distribution  of diﬀerence  between  ac- \\ntual and predicted  |   \\ntheir performance,  which is better than other deep learning  approaches'}   |   Table 5 \\nEUR/USD  30-mins performance  comparison.  \\nModels MSE RMSE MAE'}   |\n",
      "| \\nof this market.  While there are many machine  learning and deep learn- \\ning  |   result. For \\nEUR-USD  data-set  parsimonious  model provides  good results.   | curve for USD/CAD  10-mins  \\ntimeframe.  \\nclosing price of each currency  pair |   file1.pdf page: 9 {'version  showed  a 56% proﬁt. Another  hybrid model was    |      file1.pdf page: 12 {'risk associated  with it. Table 9 and 10 show the      |\n",
      "|  approaches  used in ﬁnance,  there is a constant competition  where \\ntraders   |     They as- \\nsumed that models that use stochastic  process  which evolves     |     before 10 minutes  and 30 minutes  \\nthan the actual time. Also, we have     |   developed  by \\nRajashree  [53] who used the mixture of an improved  shuﬄed    |  comparison  of the mod- \\nels in terms of 𝑅 2 scores for 10-mins  and 30-mins   |\n",
      "|    look for new techniques  to outperform  the market. This makes \\nthe novel    |      coeﬃcients \\nare best to use for this prediction.  They found reliable      | compared  our proposed  models \\nagainst  a standalone  GRU, a standalone  LSTM, | frog leap- \\ning (ISFL) and computationally  eﬃcient functional  link artiﬁcial  |   timeframe  respec- \\ntively. Our proposed  model produces  higher 𝑅 2 scores   |\n",
      "|  approaches  more demanding  as their uniqueness  helps traders \\nto meet their  |  consistency  for'} file1.pdf page: 2 {'search algorithm.  The experiment  was   |   and a statistical  model \\nthat is based on the moving  average  technique.    | neural \\nnetwork  (CEFLANN)  for prediction.  The improved  shuﬄed  frog leaping |   than both of the \\nstandalone models and SMA for all currency  pairs in both   |\n",
      "| desire in a particular  way. \\nThe rest of the article is organized  as follows. | done with two years of histori-  \\ncal data. Multiple  linear regression  (MLR)  |    \\n5.1. Performance  evaluation'} file1.pdf page: 9 {'system.  to check the    |  \\nwas used for reducing  the error rate of the system.  She used three diﬀer-   | 10-mins  and \\n30-mins timeframes.  Since 𝑅 2 score is a risk analysis  metric,  |\n",
      "|   Section  2 presents'} file1.pdf page: 1 {'5.1.1. EUR/USD  \\nFor the EUR/USD    |   provided  better results than \\nSVR, PLS, and CRT. Their model outperformed    |  performance  of the system,  two diﬀerent  algorithms  \\nShuﬄed  frog leaping   |     ent currency  pairs USD/CAD,  USD/CHF,  and USD/JPY  for her proposed'}      |     we can say \\nthat our model is more reliable  and safe than the compared     |\n",
      "| currency  pair, we validated  the model against \\n14886 samples  for our 10-mins | other regression algo- \\nrithms [18] [19] . Another  hybrid model was developed  | algorithm  and Particle  Swarm optimization  algo- \\nrithm were used. The result | file1.pdf page: 3 {'sis showed  that hybrid models performed  better than stand- | models.'} file1.pdf page: 13 {'see if our proposed  model improves  the overall  |\n",
      "|  model and 3723 samples  for our 30-mins \\nmodel that is 20% of our total data   |      by Paponpat, \\nKosin and Nattapol  [20] for statistic  inspection  and      | showed  that this proposed  model performed  \\nbetter than both of the compared  |    alone  mod- \\nels. Hybrid models provided  more accuracy  and also reduced    |     performance  and can \\noutperform  any of these algorithms  as the whole     |\n",
      "| respectively.  The model is trained \\nusing the rest of the data. Figs. 3 and 4  | prediction  that’s \\nsupported  compressed  vector autoregression.  They used a  | algorithms.  For RMSE the error rate \\nfor USD/CAD  and USD/JPY  currency  pairs |  uncer- \\ntainty. This also motivates  us to use a combination  of GRU and LSTM  | experiment  will be \\nmeaningless  if the system provides  same performance  or  |\n",
      "|   present  the distribution  of dif- \\nferences  between  actual and predicted   |                         random  com-'} file1.pdf page: 1                         |   was between  0.04–0.05  and \\nfor USD/CHF  the range was between  0.03–0.04.   |     \\nto predict FOREX price. After studying  the artiﬁcial  neural network-     |   worse than the \\nindividual  models and its not possible  to understand  the   |\n",
      "| curve provided  in Figs. 5 and \\n6 , respectively.  The x -axis represents  the  |                                                                                  |                    Similar  approach  was'} file1.pdf page: 3                    |   \\nbased hybrid models,  they found that deep learning  architecture  was the   |  diﬀerence  with- \\nout proper comparison.  Another  reason for choosing  these  |\n",
      "|                diﬀerence  between  the actual'} file1.pdf page: 9                |                                                                                  |                                                                                  | \\nless used algorithm  for currency  exchange forecasting.  Although,  recent'}  |   two models is \\ntheir performance,  which is better than other deep learning   |\n",
      "|                                                                                  |                                                                                  |                                                                                  |                                file1.pdf page: 3                                 |                          approaches'} file1.pdf page: 9                          |\n",
      "+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+\n",
      "\n",
      "\u001b[32mFilename: file2.pdf\u001b[0m\n",
      "+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+\n",
      "|                               model specification                                |                                 model estimation                                 |                                 model evaluation                                 |                                 model deployment                                 |                                 benchmark models                                 |\n",
      "+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+\n",
      "|   \u001b[32m Model specification is defined as the process of selecting the appropriate    |    \u001b[32m Model estimation is the process of using regression techniques to compare    |     \u001b[32m Model evaluation is defined as the process of comparing the actual data     |     \u001b[32m Model deployment is the process of making a model available for use in      |   \u001b[32m Benchmark models are used in the context to compare the performance of the    |\n",
      "|     model for a given dataset. In this context, a hybrid model based on the      |    actual data with predicted data in order to measure the performance of the    |    with predicted data using performance matrices such as MSE, RMSE, MAE, and    |    production. In the context, model deployment is discussed in terms of the     |  proposed hybrid model against a simple statistical model that uses the simple   |\n",
      "|    regression technique was developed by Said, Omar, and Aziz which combined     |    system. This is done by calculating the MSE, RMSE, MAE, and R-squared (R2)    |    R-squared (R2) score to measure the performance of the system. The context    |   evaluation of the system's performance by comparing the actual data with the   |   moving average of the previous 20-days closing price. The performance of the   |\n",
      "| regression techniques with the cuckoo search algorithm. This model was inspired  |    values.\u001b[0m  Sources:{'the future predictions  for 10 minutes  and 30 minutes     |  applies model evaluation by comparing the proposed models against a standalone  |  predicted data. This is done by measuring the performance of the system using   | proposed model is compared to the standalone LSTM model, a standalone GRU model, |\n",
      "|  by the autoregressive moving average (ARMA) model and the dataset was prepared  | are done and the \\nsystem’s  performance  is measured.  \\n4.4. Model validation  |   GRU, a standalone LSTM, and a statistical model based on the moving average    |  metrics such as MSE, RMSE, MAE, and R-squared value. Additionally, the context  | and a simple moving average (SMA) based statistical model in terms of MSE, RMSE, |\n",
      "| with historical data of USD/EUR currency pair. Support vector regression (SVR),  | \\nValidation  is an important  step that is used to check the performance  \\nof  |   technique.\u001b[0m  Sources:{'the future predictions  for 10 minutes  and 30 minutes   |  discusses the use of hybrid models, which combine multiple models, to improve   |   MAE, and 𝑅2 scores. The comparison of the models is used to determine which    |\n",
      "| multiple linear regression and nonparametric self-organising modelling approach  | the system by comparing  the actual data with predicted  data. Here we have used | are done and the \\nsystem’s  performance  is measured.  \\n4.4. Model validation  |    the accuracy and reduce uncertainty.\u001b[0m  Sources:{'M.S. Islam and E. Hossain     |   model is the least risky and most reliable.\u001b[0m  Sources:{'our proposed  hybrid    |\n",
      "|      were also used.\u001b[0m  Sources:{'model, these values are 0.00084,  0.02895,       |  MSE (Mean Squared  Error), RMSE (Root Mean Square Error), \\nMAE (Mean Absolute  | \\nValidation  is an important  step that is used to check the performance  \\nof  |  Soft Computing  Letters 3 (2021) 100009 \\nFig. 1. Simple architecture  of our   |     model against  a simple statistical  model that uses \\nthe simple moving     |\n",
      "|  0.01448  and 0.93690  respec- \\ntively. The actual vs predicted  value curves   |  Error), and R-squared  ( 𝑅 2 ) value for measuring  the \\nperformance  of our   | the system by comparing  the actual data with predicted  data. Here we have used |  proposed  pipeline.  \\nUSDINR.  They tested their model against  other models   |   average  of the previous  20-days  closing price. Al- \\nthough,  this model    |\n",
      "|  are provided  in Figs. 7 and \\n8 . \\nThe x-axis indicates  the number  of test  | system. Among  them in MSE and RMSE, the error'} file2.pdf page: 8 {'M.S. Islam  |  MSE (Mean Squared  Error), RMSE (Root Mean Square Error), \\nMAE (Mean Absolute  |    supported  by \\nELM, NN, and FLANN.  They found that between  ELM, NN, and    | produces  less error for EUR/USD  and USD/CHF  in \\n30-mins  timeframe,  but it  |\n",
      "| samples  (14871  for 10-mins \\nmodel and 37224 samples  for 30-mins  model) that |     and E. Hossain Soft Computing  Letters 3 (2021) 100009 \\nFig. 1. Simple      |  Error), and R-squared  ( 𝑅 2 ) value for measuring  the \\nperformance  of our   |   FLANN,  \\nELM shows the most eﬀective  optimization. Consistent  with their    |  has a very high risk associated  with it. In \\nterms of risk associated  with   |\n",
      "|   have been used for \\nprediction.  The actual closing values of the currency    |   architecture of our proposed  pipeline.  \\nUSDINR.  They tested their model    |  system. Among  them in MSE and RMSE, the error'} file2.pdf page: 8 {'than the   |  eval- \\nuation data, for MAPE evaluation  ELM DE provides rock bottom  error.   |    the return, the proposed  model maintains \\nits superiority  among all the    |\n",
      "|   pairs are marked  \\nby yellow color and model predicted  closing values are    |    against  other models supported  by \\nELM, NN, and FLANN.  They found that    |      actual time. Also, we have compared  our proposed  models \\nagainst  a      |  \\nFor MAE, ARV, and Theils U models ELM TLBO, ELM PSO and ELM Jaya'} file2.pdf  |  models for both timeframes.  Although  the'} file2.pdf page: 14 {'model, these  |\n",
      "|   marked  by blue'} file2.pdf page: 10 {'system architecture  of our proposed    |    between  ELM, NN, and FLANN,  \\nELM shows the most eﬀective  optimization.    | standalone  GRU, a standalone  LSTM, and a statistical  model \\nthat is based on |  page: 2 {'the future predictions  for 10 minutes  and 30 minutes  are done and  |    values are 0.00084,  0.02895,  0.01448  and 0.93690  respec- \\ntively. The    |\n",
      "| system.  \\n4.1. Data collection \\nThe dataset was collected  from Histdata  [65] | Consistent  with their eval- \\nuation data, for MAPE evaluation  ELM DE provides |    the moving average  technique.  \\n5.1. Performance  evaluation  \\nFor each    | the \\nsystem’s  performance  is measured.  \\n4.4. Model validation  \\nValidation | actual vs predicted  value curves are provided in Figs. 7 and \\n8 . \\nThe x-axis |\n",
      "| website.  Data was col- \\nlected for four major currency  pairs: EUR/USD  [66] , |  rock bottom  error. \\nFor MAE, ARV, and Theils U models ELM TLBO, ELM PSO and   | currency  pair, our model was trained  using the 20-256-64  \\nformation  of the  | is an important  step that is used to check the performance  \\nof the system by  |  indicates  the number  of test samples  (14871 for 10-mins  \\nmodel and 37224   |\n",
      "|   GBP/USD  [67] , \\nUSD/CAD  [68] , and USD/CHF  [69] . We have collected  two   |    ELM Jaya'} file2.pdf page: 2 {'model, these values are 0.00084,  0.02895,     | hidden layers and was run for 100 times. The predic- \\ntion was then done on the |   comparing  the actual data with predicted  data. Here we have used MSE (Mean   |  samples  for 30-mins  model) that have been used for \\nprediction.  The actual  |\n",
      "|     years of his- \\ntorical time series data from 1st January,  2017 to 31st     | 0.01448  and 0.93690 respec- \\ntively. The actual vs predicted  value curves are | 20% of the total data. Then the performance'} file2.pdf page: 9 {'ELM shows the  |  Squared  Error), RMSE (Root Mean Square Error), \\nMAE (Mean Absolute  Error),   |   closing values of the currency  pairs are marked \\nby yellow color and model   |\n",
      "|  December,  2018 \\nfor our 10 minutes  prediction  model and from 1st January,   |    provided  in Figs. 7 and \\n8 . \\nThe x-axis indicates  the number  of test    |  most eﬀective  optimization.  Consistent  with their eval- \\nuation data, for   |  and R-squared  ( 𝑅 2 ) value for measuring  the \\nperformance  of our system.   |  predicted  closing values are marked  by blue'} file2.pdf page: 10 {'Proposed   |\n",
      "| 2019 to 30th'} file2.pdf page: 7 {'exchange  market prediction.  A hybrid model  |   samples  (14871  for 10-mins  \\nmodel and 37224 samples  for 30-mins  model)   | MAPE evaluation  ELM DE provides  rock bottom  error. \\nFor MAE, ARV, and Theils |  Among  them in MSE and RMSE, the error'} file2.pdf page: 8 {'M.S. Islam and E.  |   Model 0.99205 0.93690 0.99287 0.98159 \\nLSTM 0.98358 0.92664 0.59762 0.30702   |\n",
      "| based on the regression  \\ntechnique  was developed  by Said, Omar, and Aziz who | that have been used for \\nprediction.  The actual closing values of the currency |  U models ELM TLBO, ELM PSO and ELM Jaya \\nprovided  the most eﬀective  result   |    Hossain Soft Computing  Letters 3 (2021) 100009 \\nFig. 3. Distribution  of    |   \\nGRU 0.99052 0.68449 0.90486 0.98010 \\nSMA 0.39487 0.05839 0.01325 0.21750    |\n",
      "|     used a combi- \\nnation of regression  techniques  with the cuckoo search     |   pairs are marked  \\nby yellow color and model predicted  closing values are    |     respectively.  For FOREX trading  strat- \\negy optimization,  a genetic      |     diﬀerences  between  ac- \\ntual and predicted curve for EUR/USD  10-mins     | \\nand 0.21750,  respectively)  among all the models and thus have a huge \\nrisk  |\n",
      "|    algorithm [17] . \\nTheir model was inspired  by the autoregressive  moving    |   marked  by blue'} file2.pdf page: 10 {'sion (MLR), CRT regression  tree, and   |    algorithm  was employed  by Galeshchuk  and \\nMukherjee  [34] to evolve a     |    \\ntimeframe.  \\nprovided  more stability  and accuracy  in predicting  the    |  associated  with it. Table 9 and 10 show the comparison  of the mod- \\nels in   |\n",
      "|  average (ARMA)  \\nmodel and they prepared  their dataset with historical  data  |  partial least squares  (PLS) regres- \\nsion methods  were used to train their   |   special set of proﬁtable  trading  rules inspired'} file2.pdf page: 2 {'5.1.   | rates. The analy- \\nsis showed  that hybrid models performed  better than stand- |  terms of 𝑅 2 scores for 10-mins  and 30-mins timeframe  respec- \\ntively. Our   |\n",
      "|    of USD/EUR  \\ncurrency  pair. Support  vector regression  (SVR), multiple     |   dataset.  The weights  that were \\ngenerated  by these four algorithms  were   | Performance  evaluation  \\nFor each currency  pair, our model was trained  using |    alone  mod- \\nels. Hybrid models provided  more accuracy  and also reduced    |  proposed  model produces  higher 𝑅 2 scores than both of the'} file2.pdf page:  |\n",
      "| linear regres-'} file2.pdf page: 1 {'the future predictions  for 10 minutes  and | used as the inputs of the Cuckoo  \\nsearch algorithm.  The experiment  was done  | the 20-256-64  \\nformation  of the hidden layers and was run for 100 times. The  | uncer- \\ntainty. This also motivates  us to use a combination  of GRU and LSTM'} |    13 {'exchange  market prediction.  A hybrid model based on the regression     |\n",
      "| 30 minutes  are done and the \\nsystem’s  performance  is measured.  \\n4.4. Model |    with two years of histori- \\ncal data. Multiple  linear regression  (MLR)     | predic- \\ntion was then done on the 20% of the total data. Then the performance  |  file2.pdf page: 3 {'system architecture  of our proposed  system.  \\n4.1. Data  |  \\ntechnique  was developed  by Said, Omar, and Aziz who used a combi- \\nnation  |\n",
      "|    validation  \\nValidation  is an important  step that is used to check the     |   provided  better results than \\nSVR, PLS, and CRT. Their model outperformed    | \\nwas measured  using the performance  matrices  MSE, RMSE, MAE, and \\n𝑅 2 score | collection  \\nThe dataset was collected  from Histdata  [65] website.  Data was  |   of regression  techniques  with the cuckoo search algorithm  [17] . \\nTheir    |\n",
      "| performance  \\nof the system by comparing  the actual data with predicted  data. |   other regression  algo-'} file2.pdf page: 1 {'color, and the model predicted   |    which compares  the diﬀerence  between  actual and predicted  \\nvalues and    |  col- \\nlected for four major currency  pairs: EUR/USD  [66] , GBP/USD  [67] ,   |  model was inspired  by the autoregressive moving  average  (ARMA)  \\nmodel and  |\n",
      "|   Here we have used MSE (Mean Squared  Error), RMSE (Root Mean Square Error),    | closing values are marked by blue color. \\nThe y-axis indicates  the unit value  |  provided  a result between  0 and 1. We chose the perfor-'} file2.pdf page: 9   |    \\nUSD/CAD  [68] , and USD/CHF  [69] . We have collected  two years of his-    | they prepared  their dataset with historical  data of USD/EUR  \\ncurrency  pair. |\n",
      "|  \\nMAE (Mean Absolute  Error), and R-squared  ( 𝑅 2 ) value for measuring  the   |  of this pair which in this case is the \\nnormalized  closing price of EUR/USD   |  {'M.S. Islam and E. Hossain Soft Computing  Letters 3 (2021) 100009 \\nFig. 1.   | \\ntorical time series data from 1st January,  2017 to 31st December,  2018 \\nfor |  Support  vector regression (SVR), multiple  linear regres-'} file2.pdf page: 1  |\n",
      "|     \\nperformance  of our system.  Among  them in MSE and RMSE, the error'}      |  currency  pair. The ﬂuctuation  in \\nthe curve indicates  the ups and downs of  |  Simple architecture  of our proposed  pipeline.  \\nUSDINR.  They tested their   |     our 10 minutes  prediction  model and from 1st January,  2019 to 30th'}      |   {'standalone  LSTM model, a standalone  GRU model and simple moving average    |\n",
      "|   file2.pdf page: 8 {'and nonparametric  self-organising  modelling  approach,   |   the closing prices. \\nThe graphs clearly show how accurate  the predictions    | model against  other models supported  by \\nELM, NN, and FLANN.  They found that |     file2.pdf page: 7 {'vector machine  (SVM). SVM was implemented  in both      |   (SMA) based statistical  model \\nwhere the proposed  hybrid GRU-LSTM  model    |\n",
      "|              Expert Syst. Appl. 36 (10) \\n(2009) 12001–12011,  doi:              |  are: actual \\nand predicted  values almost overlap  with each other. The MSE,   |    between  ELM, NN, and FLANN,  \\nELM shows the most eﬀective  optimization.    | individual  and \\nhybrid systems  with prediction capabilities.  Thuy and Vuong  |   outperforms  all models for 10-mins timeframe  and for 30-mins  \\ntimeframe    |\n",
      "|   10.1016/j.eswa.2009.03.057  . \\n[4] R.D. Huang, R.W. Masulis, Fx spreads and   |  RMSE, \\nand MAE scores of our model for EUR/USD  10-mins  pairs are 0.00001,'}  | Consistent  with their eval- \\nuation data, for MAPE evaluation  ELM DE provides | [28] pro- \\nposed a model for foreign exchange prediction  using SVM. They used  |  provides  the best result for GBP/USD and USD/CAD  currency  pairs in terms of  |\n",
      "| dealer competition  across the 24-hour \\ntrading day, Rev. Financ. Stud. 12 (1)  |  file2.pdf page: 9 {'exchange  market prediction.  A hybrid model based on the   |  rock bottom  error. \\nFor MAE, ARV, and Theils U models ELM TLBO, ELM PSO and   | \\nthe EUR/USD  currency  pair for their models implementation.  They used \\nthe  | MSE, RMSE, and MAE \\nperformance metrics.  But in terms of 𝑅 2 score, our system |\n",
      "|  (1999) 61–93, doi: 10.1093/rfs/12.1.61  . \\n[5] S. Masry, A. Dupuis, R. Olsen,  | regression \\ntechnique  was developed  by Said, Omar, and Aziz who used a combi- | ELM Jaya'} file2.pdf page: 2 {'data from January  1, 2019 to June 30, 2020 as a  | cross-validation  method  for their data-set and divided  the results \\ninto two |   outperforms  all compared models and thus proves \\nitself as the least risky   |\n",
      "|  E. Tsang, Time zone normalization  of fx seasonality,  \\nQuant. Finance 13 (7)  |   \\nnation of regression  techniques  with the cuckoo search algorithm  [17] .   |   proof-of-concept.  The performance  of the model is validated  \\nusing MSE,    |   categories  positive  output and negative output.  They used ac-'} file2.pdf   |    model among all. \\n1. Introduction'} file2.pdf page: 0 {'USD/CAD  10-mins     |\n",
      "|   (2013) 1115–1123,  doi: 10.1080/14697688.2013.773458  .'} file2.pdf page: 15   |    \\nTheir model was inspired  by the autoregressive  moving  average  (ARMA)    |  RMSE, MAE, and 𝑅 2 score. Moreover,  we have compared  the performance  of our  |  page: 1 {'see if our proposed  model improves the overall performance  and can  | performance  comparison. \\nModels MSE RMSE MAE \\nProposed  Model 0.00004 0.00597 |\n",
      "|  {'M.S. Islam and E. Hossain Soft Computing  Letters 3 (2021) 100009 \\nFig. 1.   |    \\nmodel and they prepared  their dataset with historical  data of USD/EUR     |   model against a \\nstandalone  LSTM model, a standalone  GRU model and simple   |     \\noutperform  any of these algorithms  as the whole experiment  will be      |    0.00387 \\nLSTM 0.00005 0.00686 0.00464 \\nGRU 0.00041 0.02024 0.01721 \\nSMA    |\n",
      "|  Simple architecture  of our proposed  pipeline.  \\nUSDINR.  They tested their   | \\ncurrency  pair. Support  vector regression  (SVR), multiple  linear regres-'}  | moving average (SMA) based statistical  model \\nwhere the proposed  hybrid GRU-  |    \\nmeaningless  if the system provides  same performance  or worse than the    |  0.00008 0.00936 0.00788 \\nTable 4 \\nUSD/CHF  10-mins  performance  comparison.  |\n",
      "| model against  other models supported  by \\nELM, NN, and FLANN.  They found that |  file2.pdf page: 1 {'their proposed  model they found that autoregression  with  |  LSTM  model outperforms  all models for 10-mins  timeframe  and for 30-mins'}   |  \\nindividual  models and its not possible  to understand  the diﬀerence  with-  |  \\nModel MSE RMSE MAE \\nProposed  Model 0.00001 0.00362 0.00261 \\nLSTM 0.00001   |\n",
      "|    between  ELM, NN, and FLANN,  \\nELM shows the most eﬀective  optimization.    |  four lags also \\nreferred  to as AR(4) and time-varying  autoregression  with   |  file2.pdf page: 0 {'M.S. Islam and E. Hossain Soft Computing  Letters 3 (2021)  |   \\nout proper comparison.  Another  reason for choosing  these two models is    |   0.00385 0.00281 \\nGRU 0.00036 0.01888 0.01516 \\nSMA 0.00006 0.00825 0.00649    |\n",
      "| Consistent  with their eval- \\nuation data, for MAPE evaluation  ELM DE provides |  four lags, re- \\nferred to as TVP-AR(4)  model gives best USD-JYP  prediction   | 100009 \\nFig. 11. Distribution  of diﬀerence  between  ac- \\ntual and predicted  |   \\ntheir performance,  which is better than other deep learning  approaches'}   |   Table 5 \\nEUR/USD  30-mins performance  comparison.  \\nModels MSE RMSE MAE'}   |\n",
      "|  rock bottom  error. \\nFor MAE, ARV, and Theils U models ELM TLBO, ELM PSO and   |   result. For \\nEUR-USD  data-set  parsimonious  model provides  good results.   | curve for USD/CAD  10-mins  \\ntimeframe.  \\nclosing price of each currency  pair |   file2.pdf page: 9 {'version  showed  a 56% proﬁt. Another  hybrid model was    |      file2.pdf page: 12 {'risk associated  with it. Table 9 and 10 show the      |\n",
      "| ELM Jaya'} file2.pdf page: 2 {'searchers  are trying to come up with new models  |     They as- \\nsumed that models that use stochastic  process  which evolves     |     before 10 minutes  and 30 minutes  \\nthan the actual time. Also, we have     |   developed  by \\nRajashree  [53] who used the mixture of an improved  shuﬄed    |  comparison  of the mod- \\nels in terms of 𝑅 2 scores for 10-mins  and 30-mins   |\n",
      "| to predict the nature \\nof this market.  While there are many machine  learning  |      coeﬃcients \\nare best to use for this prediction.  They found reliable      | compared  our proposed  models \\nagainst  a standalone  GRU, a standalone  LSTM, | frog leap- \\ning (ISFL) and computationally  eﬃcient functional  link artiﬁcial  |   timeframe  respec- \\ntively. Our proposed  model produces  higher 𝑅 2 scores   |\n",
      "|      and deep learn- \\ning approaches  used in ﬁnance,  there is a constant      |  consistency  for'} file2.pdf page: 2 {'search algorithm.  The experiment  was   |   and a statistical  model \\nthat is based on the moving  average  technique.    | neural \\nnetwork  (CEFLANN)  for prediction.  The improved  shuﬄed  frog leaping |   than both of the \\nstandalone models and SMA for all currency  pairs in both   |\n",
      "| competition  where \\ntraders look for new techniques  to outperform  the market. | done with two years of histori-  \\ncal data. Multiple  linear regression  (MLR)  |    \\n5.1. Performance  evaluation'} file2.pdf page: 9 {'system.  to check the    |  \\nwas used for reducing  the error rate of the system.  She used three diﬀer-   | 10-mins  and \\n30-mins timeframes.  Since 𝑅 2 score is a risk analysis  metric,  |\n",
      "|  This makes \\nthe novel approaches  more demanding  as their uniqueness  helps   |   provided  better results than \\nSVR, PLS, and CRT. Their model outperformed    |  performance  of the system,  two diﬀerent  algorithms  \\nShuﬄed  frog leaping   |     ent currency  pairs USD/CAD,  USD/CHF,  and USD/JPY  for her proposed'}      |     we can say \\nthat our model is more reliable  and safe than the compared     |\n",
      "|  traders \\nto meet their desire in a particular  way. \\nThe rest of the article  | other regression algo- \\nrithms [18] [19] . Another  hybrid model was developed  | algorithm  and Particle  Swarm optimization  algo- \\nrithm were used. The result | file2.pdf page: 3 {'sis showed  that hybrid models performed  better than stand- | models.'} file2.pdf page: 13 {'see if our proposed  model improves  the overall  |\n",
      "|   is organized  as follows.  Section  2 presents'} file2.pdf page: 1 {'5.1.1.    |      by Paponpat, \\nKosin and Nattapol  [20] for statistic  inspection  and      | showed  that this proposed  model performed  \\nbetter than both of the compared  |    alone  mod- \\nels. Hybrid models provided  more accuracy  and also reduced    |     performance  and can \\noutperform  any of these algorithms  as the whole     |\n",
      "|   EUR/USD  \\nFor the EUR/USD  currency  pair, we validated  the model against    | prediction  that’s \\nsupported  compressed  vector autoregression.  They used a  | algorithms.  For RMSE the error rate \\nfor USD/CAD  and USD/JPY  currency  pairs |  uncer- \\ntainty. This also motivates  us to use a combination  of GRU and LSTM  | experiment  will be \\nmeaningless  if the system provides  same performance  or  |\n",
      "|    \\n14886 samples  for our 10-mins  model and 3723 samples  for our 30-mins     |                         random  com-'} file2.pdf page: 1                         |   was between  0.04–0.05  and \\nfor USD/CHF  the range was between  0.03–0.04.   |     \\nto predict FOREX price. After studying  the artiﬁcial  neural network-     |   worse than the \\nindividual  models and its not possible  to understand  the   |\n",
      "|    \\nmodel that is 20% of our total data respectively.  The model is trained     |                                                                                  |                    Similar  approach  was'} file2.pdf page: 3                    |   \\nbased hybrid models,  they found that deep learning  architecture  was the   |  diﬀerence  with- \\nout proper comparison.  Another  reason for choosing  these  |\n",
      "|  \\nusing the rest of the data. Figs. 3 and 4 present  the distribution  of dif-  |                                                                                  |                                                                                  | \\nless used algorithm  for currency  exchange forecasting.  Although,  recent'}  |   two models is \\ntheir performance,  which is better than other deep learning   |\n",
      "| \\nferences  between  actual and predicted  curve provided  in Figs. 5 and \\n6 ,  |                                                                                  |                                                                                  |                                file2.pdf page: 3                                 |                          approaches'} file2.pdf page: 9                          |\n",
      "|   respectively.  The x -axis represents  the diﬀerence  between  the actual'}    |                                                                                  |                                                                                  |                                                                                  |                                                                                  |\n",
      "|                                file2.pdf page: 9                                 |                                                                                  |                                                                                  |                                                                                  |                                                                                  |\n",
      "+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Generate Output Table\n",
    "output_table = qa_single_file_iterated(folder_path=folder_path, \n",
    "            chain_type=\"stuff\",\n",
    "            chunk_size=500, \n",
    "            queries=queries, \n",
    "            k=8, \n",
    "            own_knowledge = False, \n",
    "            show_pages=False)\n",
    "\n",
    "# Print Output Table\n",
    "for table_key, table_value in output_table.items():\n",
    "    print(colored(f\"Filename: {table_key}\", \"green\"))\n",
    "    print(table_value)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ```qa_all_at_once```\n",
    "Searches for the answer through all documents. Can also take the chat history into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_all_at_once(folder_path, chain_type, chunk_size, query, k, own_knowledge = False, show_pages=False):\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Read-in and split the documents\n",
    "    \"\"\"\n",
    "    all_pages = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        if file_name.endswith('.pdf'):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif file_name.endswith('.csv'):\n",
    "            loader = CSVLoader(file_path)\n",
    "        elif file_name.endswith('.docx'):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        elif file_name.endswith('.md'):\n",
    "            loader = UnstructuredMarkdownLoader(file_path)\n",
    "        else:\n",
    "            continue  # Skip files with other extensions\n",
    "\n",
    "        file = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_size/2)\n",
    "        pages = text_splitter.split_documents(file)\n",
    "        all_pages.extend(pages)\n",
    "\n",
    "    if show_pages:\n",
    "        print(len(all_pages))\n",
    "        for page in all_pages:\n",
    "            print(page)\n",
    "\n",
    "    \"\"\"\n",
    "    Vectorstores\n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    db = FAISS.from_documents(all_pages, embeddings)\n",
    "    # FAISS vectorstores can also be merged and saved to disk\n",
    "\n",
    "    \"\"\"\n",
    "    Retriever\n",
    "    \"\"\"\n",
    "    # Amount of returned documents k\n",
    "    retriever = db.as_retriever(\n",
    "        search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "\n",
    "    \"\"\"\n",
    "    Chains\n",
    "    \"\"\"\n",
    "\n",
    "    # Define Chain\n",
    "    if own_knowledge:\n",
    "        prompt_template = \"\"\"Use the following pieces of chat history and context to answer the question at the end. \\\n",
    "            If the answer does not become clear from the context, you can also use your own knowledge. \\\n",
    "            If you use your own knowledge, please indicate this clearly in your answer. \\\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        {question}\n",
    "        Helpful answer:\"\"\"\n",
    "\n",
    "    if not own_knowledge:\n",
    "\n",
    "        prompt_template = \"\"\"Use the following pieces of chat history and context to answer the question at the end. \\\n",
    "            Do NOT use your own knowledge and give the best possible answer from the context.\\\n",
    "        \n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        {question}\n",
    "        Helpful answer:\"\"\"\n",
    "\n",
    "\n",
    "    PROMPT = PromptTemplate(\n",
    "        template=prompt_template, input_variables=[\"context\",\"question\"]\n",
    "    )\n",
    "\n",
    "    chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "    # Define Chain\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=OpenAI(temperature=0),\n",
    "        chain_type=chain_type,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs=chain_type_kwargs\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Run Chain with parameters\n",
    "    result = qa(query)\n",
    "\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the chat history: \n",
      " {} \n",
      "And this is the current question: \n",
      " What is a LSTM model?.\n"
     ]
    }
   ],
   "source": [
    "# Define the Query\n",
    "query = \"What is a LSTM model?\"\n",
    "\n",
    "# Update the query with the Chat History\n",
    "query_with_context = f\"This is the chat history: \\n {str(chat_history)} \\nAnd this is the current question: \\n {query}.\"\n",
    "print(query_with_context)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Results\n",
    "In case you do not want the chat history to be part of the prompt, change ```query=query```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------\n",
      "\u001b[32mAnswer:\u001b[0m\n",
      "--------------------------------------------------------------------\n",
      "\n",
      " A Long Short-Term Memory (LSTM) model is a type of Recurrent Neural Network\n",
      "(RNN) that is capable of learning long-term dependencies. It is composed of four\n",
      "layers: an input layer, a memory unit, a cell state, and an output layer. The\n",
      "key component of the LSTM is the cell state, which runs straight down the entire\n",
      "timesteps with only minor but important interactions. LSTM can add or remove\n",
      "information from the cell state using several gates, each of which is made of a\n",
      "sigmoid neural network layer. These sigmoid layers produce output numbers\n",
      "between 0 and 1, which represent how much information is kept or removed from\n",
      "the cell state. LSTM models can be trained using an optimization algorithm like\n",
      "gradient descent on a set of training sequences.\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\u001b[32mSources:\u001b[0m\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "('file1.pdf', 'page: 5')\n",
      "('file2.pdf', 'page: 5')\n",
      "('file1.pdf', 'page: 5')\n",
      "('file2.pdf', 'page: 5')\n"
     ]
    }
   ],
   "source": [
    "# Get Results\n",
    "result = qa_all_at_once(folder_path=folder_path, \n",
    "            chain_type=\"stuff\",\n",
    "            chunk_size=1000, \n",
    "            query=query_with_context, \n",
    "            k=4, \n",
    "            own_knowledge = True, \n",
    "            show_pages=False)\n",
    "\n",
    "# Append Queries and Answers to Chat History\n",
    "chat_history[query] = result['result']\n",
    "\n",
    "# Define Sources\n",
    "sources = [(os.path.basename(doc.metadata[\"source\"]), f\"page: {doc.metadata['page']}\") for doc in result['source_documents']]\n",
    "\n",
    "# Print Answer and Sources\n",
    "print(\"\\n--------------------------------------------------------------------\")\n",
    "print(colored(\"Answer:\", \"green\"))\n",
    "print(\"--------------------------------------------------------------------\\n\")\n",
    "print(textwrap.fill(result['result'], width=80))\n",
    "print(\"\\n--------------------------------------------------------------------\")\n",
    "print(colored(\"Sources:\", \"green\"))\n",
    "print(\"--------------------------------------------------------------------\\n\")\n",
    "for source in sources:\n",
    "    print(source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
