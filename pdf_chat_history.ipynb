{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tabulate numpy pandas langchain openai chromadb pypdf tiktoken faiss-cpu Flask unstructured Cython pdfminer.six termcolor tabulate tqdm reportlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document loaders\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "# Splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "# Embeddings and models\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import FAISS, Chroma\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "# Chains\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "# Utils\n",
    "import os\n",
    "from termcolor import colored\n",
    "import textwrap\n",
    "from prettytable import PrettyTable\n",
    "import ast\n",
    "from tqdm.auto import tqdm\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Import API Key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folder Path Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r\"C:\\Users\\cesar\\OneDrive\\Desktop\\test2\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ```qa_single_file```\n",
    "This iterates over each file seperately, asking each one the same question. Good for literature overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_single_file(folder_path, chain_type, chunk_size, query, k, own_knowledge = False, show_pages=False):\n",
    "\n",
    "    # Define output table.\n",
    "    tables = {}\n",
    "\n",
    "    # Wraptext function for prettytable\n",
    "    def wrap_text(text, width=40):\n",
    "        return \"\\n\".join(textwrap.wrap(text, width=width))\n",
    "\n",
    "    \"\"\"\n",
    "    Read-in and split the documents\n",
    "    \"\"\"\n",
    "    # Loop over all files in folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        # Clear all_pages\n",
    "        all_pages = []\n",
    "\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        if file_name.endswith('.pdf'):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif file_name.endswith('.csv'):\n",
    "            loader = CSVLoader(file_path)\n",
    "        elif file_name.endswith('.docx'):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        elif file_name.endswith('.md'):\n",
    "            loader = UnstructuredMarkdownLoader(file_path)\n",
    "        else:\n",
    "            continue  # Skip files with other extensions\n",
    "\n",
    "        file = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_size/2)\n",
    "        pages = text_splitter.split_documents(file)\n",
    "        all_pages.extend(pages)\n",
    "\n",
    "        if show_pages:\n",
    "            print(len(all_pages))\n",
    "            for page in all_pages:\n",
    "                print(page)\n",
    "\n",
    "        \"\"\"\n",
    "        Vectorstores\n",
    "        \"\"\"\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "\n",
    "        db = FAISS.from_documents(all_pages, embeddings)\n",
    "        # FAISS vectorstores can also be merged and saved to disk\n",
    "\n",
    "        \"\"\"\n",
    "        Retriever\n",
    "        \"\"\"\n",
    "        # Amount of returned documents k\n",
    "        retriever = db.as_retriever(\n",
    "            search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "\n",
    "        \"\"\"\n",
    "        Chains\n",
    "        \"\"\"\n",
    "\n",
    "        # Define Chain\n",
    "        if own_knowledge:\n",
    "            prompt_template = \"\"\"Use the following pieces of context to find an answer to all the keys given in the question. \\\n",
    "                Give your answer in the form of a dictionary with the keys given in the question. \\\n",
    "                If the answer does not become clear from the context, you can also use your own knowledge. \\\n",
    "                If you use your own knowledge, please indicate this clearly in your answer. \\\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            {question}\n",
    "            Helpful answer:\"\"\"\n",
    "\n",
    "        if not own_knowledge:\n",
    "\n",
    "            prompt_template = \"\"\"Use the following pieces of context to find an answer to all the keys given in the question. \\\n",
    "                Give your answer in the form of a dictionary with the keys given in the question. \\\n",
    "                Do NOT use your own knowledge and give the best possible answer from the context.\\\n",
    "            \n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            {question}\n",
    "            Helpful answer:\"\"\"\n",
    "\n",
    "\n",
    "        PROMPT = PromptTemplate(\n",
    "            template=prompt_template, input_variables=[\"context\",\"question\"]\n",
    "        )\n",
    "\n",
    "        chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "        # Define Chain\n",
    "        qa = RetrievalQA.from_chain_type(\n",
    "            llm=OpenAI(temperature=0),\n",
    "            chain_type=chain_type,\n",
    "            retriever=retriever,\n",
    "            return_source_documents=True,\n",
    "            chain_type_kwargs=chain_type_kwargs\n",
    "        )\n",
    "        \n",
    "\n",
    "        # Run Chain with parameters\n",
    "        result = qa(query)\n",
    "\n",
    "        # Convert string representation of dictionary to an actual dictionary\n",
    "        result_dict = ast.literal_eval(result['result'])\n",
    "\n",
    "        # Get Sources\n",
    "        sources = [(os.path.basename(doc.metadata[\"source\"]), f\"page: {doc.metadata['page']}\") for doc in result['source_documents']]\n",
    "\n",
    "        # Append result to output tables\n",
    "        table_key = (file_name, tuple(sources))\n",
    "        if table_key not in tables:\n",
    "            table_columns = [\"Filename\", \"Sources\"] + list(result_dict.keys())\n",
    "            tables[table_key] = PrettyTable(table_columns)\n",
    "        table_row = [wrap_text(table_key[0]), wrap_text(', '.join([f'{source[0]} {source[1]}' for source in table_key[1]]))] + [wrap_text(str(value)) for value in result_dict.values()]\n",
    "        tables[table_key].add_row(table_row)\n",
    "\n",
    "    # Return output tables\n",
    "    return tables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"model specification, model estimation, model evaluation, model deployment, benchmark models\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Results\n",
    "Use smaller chunk sizes to catch more different part in one prompt. Use at least as many chunks (k) as there are keys in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFilename: file1.pdf\u001b[0m\n",
      "+-----------+----------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "|  Filename |                Sources                 |          model specification          |             model estimation             |             model evaluation             |             model deployment             |             benchmark models            |\n",
      "+-----------+----------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "| file1.pdf | file1.pdf page: 8, file1.pdf page: 13, |    Support vector regression (SVR),   | The weights that were generated by these | Validation is an important step that is  | Based on the saved weighted values, the  |  They tested their model against other  |\n",
      "|           | file1.pdf page: 2, file1.pdf page: 1,  | multiple linear regression (MLR), CRT | four algorithms were used as the inputs  |   used to check the performance of the   | future predictions for 10 minutes and 30 | models supported by ELM, NN, and FLANN. |\n",
      "|           |           file1.pdf page: 1            |   regression tree, and partial least  |     of the Cuckoo search algorithm.      | system by comparing the actual data with |    minutes are done and the systemâ€™s     |   They found that between ELM, NN, and  |\n",
      "|           |                                        | squares (PLS) regression methods were |                                          |  predicted data. Here we have used MSE   |         performance is measured.         |   FLANN, ELM shows the most effective   |\n",
      "|           |                                        |      used to train their dataset.     |                                          |  (Mean Squared Error), RMSE (Root Mean   |                                          |              optimization.              |\n",
      "|           |                                        |                                       |                                          |    Square Error), MAPE (Mean Absolute    |                                          |                                         |\n",
      "|           |                                        |                                       |                                          |  Percentage Error), MAE (Mean Absolute   |                                          |                                         |\n",
      "|           |                                        |                                       |                                          |      Error), ARV (Absolute Relative      |                                          |                                         |\n",
      "|           |                                        |                                       |                                          |         Variance), and Theils U.         |                                          |                                         |\n",
      "+-----------+----------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "\n",
      "\u001b[32mFilename: file2.pdf\u001b[0m\n",
      "+-----------+----------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "|  Filename |                Sources                 |          model specification          |             model estimation             |             model evaluation             |             model deployment             |             benchmark models            |\n",
      "+-----------+----------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "| file2.pdf | file2.pdf page: 8, file2.pdf page: 13, |    Support vector regression (SVR),   | The weights that were generated by these | Validation is an important step that is  | Based on the saved weighted values, the  |  They tested their model against other  |\n",
      "|           | file2.pdf page: 2, file2.pdf page: 1,  | multiple linear regression (MLR), CRT | four algorithms were used as the inputs  |   used to check the performance of the   | future predictions for 10 minutes and 30 | models supported by ELM, NN, and FLANN. |\n",
      "|           |           file2.pdf page: 1            |   regression tree, and partial least  |     of the Cuckoo search algorithm.      | system by comparing the actual data with |    minutes are done and the systemâ€™s     |   They found that between ELM, NN, and  |\n",
      "|           |                                        | squares (PLS) regression methods were |                                          |  predicted data. Here we have used MSE   |         performance is measured.         |   FLANN, ELM shows the most effective   |\n",
      "|           |                                        |      used to train their dataset.     |                                          |  (Mean Squared Error), RMSE (Root Mean   |                                          |              optimization.              |\n",
      "|           |                                        |                                       |                                          |    Square Error), MAPE (Mean Absolute    |                                          |                                         |\n",
      "|           |                                        |                                       |                                          |  Percentage Error), MAE (Mean Absolute   |                                          |                                         |\n",
      "|           |                                        |                                       |                                          |      Error), ARV (Absolute Relative      |                                          |                                         |\n",
      "|           |                                        |                                       |                                          |         Variance), and Theils U.         |                                          |                                         |\n",
      "+-----------+----------------------------------------+---------------------------------------+------------------------------------------+------------------------------------------+------------------------------------------+-----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate Output Table\n",
    "output_table = qa_single_file(folder_path=folder_path, \n",
    "            chain_type=\"stuff\",\n",
    "            chunk_size=500, \n",
    "            query=query, \n",
    "            k=5, \n",
    "            own_knowledge = True, \n",
    "            show_pages=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Print Output Table\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfor\u001b[39;00m table_key, table_value \u001b[39min\u001b[39;00m output_table\u001b[39m.\u001b[39mitems():\n\u001b[0;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(colored(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFilename: \u001b[39m\u001b[39m{\u001b[39;00mtable_key[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(table_value)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output_table' is not defined"
     ]
    }
   ],
   "source": [
    "# Print Output Table\n",
    "for table_key, table_value in output_table.items():\n",
    "    print(colored(f\"Filename: {table_key[0]}\", \"green\"))\n",
    "    print(table_value)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ```qa_single_file_iterated```\n",
    "This iterates over each file **and key** seperately to be even more accurate with the single answers, asking each one the same question. Good for literature overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_single_file_iterated(folder_path, chain_type, queries, k, num_iterations, max_tokens, own_knowledge = False, show_pages=False):\n",
    "\n",
    "    # Define output table.\n",
    "    tables = {}\n",
    "\n",
    "    \"\"\"\n",
    "    Read-in and split the documents\n",
    "    \"\"\"\n",
    "    # Loop over all files in folder\n",
    "    for file_name in tqdm(os.listdir(folder_path), desc=\"Processing files\",  colour=\"green\", leave=False):\n",
    "        # Define table for filename\n",
    "        tables[file_name] = {}\n",
    "\n",
    "        # Clear all_pages\n",
    "        all_pages = []\n",
    "\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        if file_name.endswith('.pdf'):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif file_name.endswith('.csv'):\n",
    "            loader = CSVLoader(file_path)\n",
    "        elif file_name.endswith('.docx'):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        elif file_name.endswith('.md'):\n",
    "            loader = UnstructuredMarkdownLoader(file_path)\n",
    "        else:\n",
    "            continue  # Skip files with other extensions\n",
    "\n",
    "        file = loader.load()\n",
    "\n",
    "        \"\"\"\n",
    "        Prompts\n",
    "        \"\"\"\n",
    "\n",
    "        # Define Chain\n",
    "        if own_knowledge:\n",
    "            prompt_template = \"\"\"Use the following pieces of context to find an answer to the given question. \\\n",
    "                If the answer does not become clear from the context, you can also use your own knowledge. \\\n",
    "                If you use your own knowledge, please indicate this clearly in your answer. \\\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            Question:\n",
    "            Based on the context, how does the context define and apply: {question}?\n",
    "            Helpful answer:\"\"\"\n",
    "\n",
    "        if not own_knowledge:\n",
    "\n",
    "            prompt_template = \"\"\"Use the following pieces of context to find an answer to the given question. \\\n",
    "                Do NOT use your own knowledge and give the best possible answer from the context.\\\n",
    "            \n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            Question:\n",
    "            Based on the context, how does the context define and apply: {question}?\n",
    "            Helpful answer:\"\"\"\n",
    "\n",
    "\n",
    "        PROMPT = PromptTemplate(\n",
    "            template=prompt_template, input_variables=[\"context\",\"question\"]\n",
    "        )\n",
    "\n",
    "        chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "        \"\"\"\n",
    "        Retriever\n",
    "        \"\"\"\n",
    "        \n",
    "        # Define summary chain\n",
    "        text_splitter = CharacterTextSplitter()\n",
    "        qa_condense = load_summarize_chain(llm=OpenAI(temperature=0), chain_type=\"stuff\")\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        Application of Chains\n",
    "        \"\"\"\n",
    "\n",
    "        # Iterate over each query\n",
    "        for query in queries:\n",
    "\n",
    "            extended_answers = []\n",
    "            unique_sources = set()\n",
    "\n",
    "            for i in range(num_iterations):\n",
    "\n",
    "                # Define the chunk size\n",
    "                num_chunks = k-i\n",
    "\n",
    "                # Amount of tokens that GPT-3.5 can handle. This can be upped later on.\n",
    "                chunk_size = int(max_tokens/num_chunks)-1\n",
    "\n",
    "                \"\"\"\n",
    "                Load and split the documents\n",
    "                \"\"\"\n",
    "                \n",
    "                # Make the chunk size dependent on the number of chunks\n",
    "                text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_size/2)\n",
    "                pages = text_splitter.split_documents(file)\n",
    "                all_pages.extend(pages)\n",
    "\n",
    "                if show_pages:\n",
    "                    print(len(all_pages))\n",
    "                    for page in all_pages:\n",
    "                        print(page)\n",
    "\n",
    "                \"\"\"\n",
    "                Vectorstores\n",
    "                \"\"\"\n",
    "                embeddings = OpenAIEmbeddings()\n",
    "\n",
    "                db = FAISS.from_documents(all_pages, embeddings)\n",
    "                # FAISS vectorstores can also be merged and saved to disk\n",
    "\n",
    "                \"\"\"\n",
    "                Define Chain\n",
    "                \"\"\"\n",
    "\n",
    "                # QA chain that is adaptable\n",
    "                # Amount of returned documents k-i -> makes it adaptable. Otherwise, it would always return k documents and the output would be the same.\n",
    "                retriever = db.as_retriever(\n",
    "                    search_type=\"similarity\", search_kwargs={\"k\": num_chunks})\n",
    "\n",
    "                # Define retrieval chain\n",
    "                qa = RetrievalQA.from_chain_type(\n",
    "                    llm=OpenAI(temperature=0),\n",
    "                    chain_type=chain_type,\n",
    "                    retriever=retriever,\n",
    "                    return_source_documents=True,\n",
    "                    chain_type_kwargs=chain_type_kwargs\n",
    "                )\n",
    "\n",
    "                # Run Chain with parameters\n",
    "                result = qa(query)\n",
    "\n",
    "                # Get Sources\n",
    "                sources = [(doc.page_content, os.path.basename(doc.metadata[\"source\"]), f\"page: {doc.metadata['page']}\") for doc in\n",
    "                        result['source_documents']]\n",
    "\n",
    "                # Append result to extended_answers\n",
    "                extended_answers.append(result['result'])\n",
    "\n",
    "                # Add sources to the unique_sources set\n",
    "                unique_sources.update(sources)\n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "            Final dfs\n",
    "            \"\"\"\n",
    "            # Combine extended_answers\n",
    "            combined_result = ' '.join(extended_answers)\n",
    "\n",
    "            # Run the qa function on the combined_result (summary)\n",
    "            texts = text_splitter.split_text(combined_result)\n",
    "            docs = [Document(page_content=t) for t in texts[:3]]\n",
    "            \n",
    "            condensed_result = str(qa_condense.run(docs))\n",
    "\n",
    "            # Combine unique_sources\n",
    "            combined_sources = {tuple([source[1], source[2]]): source[0] for source in unique_sources}\n",
    "\n",
    "            \"\"\"\n",
    "            Store in tables\n",
    "            \"\"\"\n",
    "            # Store the results in the tables dictionary\n",
    "            tables[file_name][query] = {\n",
    "                \"combined_results\": combined_result,\n",
    "                \"condensed_result\": condensed_result,\n",
    "                \"combined_sources\": combined_sources\n",
    "            }\n",
    "\n",
    "\n",
    "    # Return output tables\n",
    "    return tables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"model specification\", \"model estimation\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Results\n",
    "Use smaller chunk sizes to catch more different part in one prompt. Use at least as many chunks (k) as there are keys in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|\u001b[32m          \u001b[0m| 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 500\n",
      "7 571\n",
      "8 500\n",
      "7 571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               9.52s/it]\r"
     ]
    }
   ],
   "source": [
    "# Generate Output Table\n",
    "output_table = qa_single_file_iterated(folder_path=folder_path, \n",
    "            chain_type=\"stuff\",\n",
    "            queries=queries, \n",
    "            k=8, \n",
    "            num_iterations=2,\n",
    "            max_tokens=4000,\n",
    "            own_knowledge = False, \n",
    "            show_pages=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: file1.pdf\n",
      "+------------------+------------------------------------------+------------------------------------------+\n",
      "| Type             | model specification                      | model estimation                         |\n",
      "+==================+==========================================+==========================================+\n",
      "| Combined_results | The context defines model                | Model estimation is the process of       |\n",
      "|                  | specification as the combination of      | using a model to compare the actual data |\n",
      "|                  | regression techniques with the cuckoo    | with the predicted data in order to      |\n",
      "|                  | search algorithm, inspired by the        | measure the performance of the system.   |\n",
      "|                  | autoregressive moving average (ARMA)     | This is done by using metrics such as    |\n",
      "|                  | model, to predict the exchange market.   | MSE, RMSE, MAE, and R-squared (R2)       |\n",
      "|                  | The model is validated against 14886     | value.  Model estimation is the process  |\n",
      "|                  | samples for the 10-minute model and 3723 | of using the validation data to measure  |\n",
      "|                  | samples for the 30-minute model. The     | the performance of the system by         |\n",
      "|                  | performance of the system is measured    | comparing the actual data with the       |\n",
      "|                  | using MSE, RMSE, MAE, and R-squared      | predicted data. This is done by using    |\n",
      "|                  | values.  Model specification is defined  | metrics such as MSE, RMSE, MAE, and      |\n",
      "|                  | as the process of defining the           | R-squared (R2) value.                    |\n",
      "|                  | parameters and rules of a model, such as |                                          |\n",
      "|                  | the trading rules used in a rule-based   |                                          |\n",
      "|                  | model, the multidimensional string       |                                          |\n",
      "|                  | models used in a pattern-based model,    |                                          |\n",
      "|                  | and the combination of regression        |                                          |\n",
      "|                  | techniques and cuckoo search algorithm   |                                          |\n",
      "|                  | used in a hybrid model. The performance  |                                          |\n",
      "|                  | of the model is then measured using      |                                          |\n",
      "|                  | metrics such as MSE, RMSE, MAE, and      |                                          |\n",
      "|                  | R-squared value.                         |                                          |\n",
      "+------------------+------------------------------------------+------------------------------------------+\n",
      "| Condensed_result | This paper presents a hybrid model       | Model estimation is the process of       |\n",
      "|                  | combining regression techniques with the | using validation data to measure the     |\n",
      "|                  | cuckoo search algorithm, inspired by the | performance of a system by comparing the |\n",
      "|                  | ARMA model, to predict the exchange      | actual data with the predicted data,     |\n",
      "|                  | market. The model is validated against   | using metrics such as MSE, RMSE, MAE,    |\n",
      "|                  | 14886 and 3723 samples for 10-minute and | and R-squared (R2) value.                |\n",
      "|                  | 30-minute models respectively, and its   |                                          |\n",
      "|                  | performance is measured using MSE, RMSE, |                                          |\n",
      "|                  | MAE, and R-squared values.               |                                          |\n",
      "+------------------+------------------------------------------+------------------------------------------+\n",
      "| Combined_sources | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 2\u001b[0m                        | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 2\u001b[0m                        |\n",
      "|                  | M.S. Islam and E. Hossain Soft Computing | uation data, for MAPE evaluation  ELM DE |\n",
      "|                  | Letters 3 (2021) 100009  Fig. 1. Simple  | provides  rock bottom  error.  For MAE,  |\n",
      "|                  | architecture  of our proposed  pipeline. | ARV, and Theils U models ELM TLBO, ELM   |\n",
      "|                  | USDINR.  They tested their model against | PSO and ELM Jaya  provided  the most     |\n",
      "|                  | other models supported  by  ELM, NN, and | eï¬€ective  result respectively.  For      |\n",
      "|                  | FLANN.  They found that between  ELM,    | FOREX trading  strat-  egy optimization, |\n",
      "|                  | NN, and FLANN,   ELM shows the most      | a genetic  algorithm  was employed  by   |\n",
      "|                  | eï¬€ective  optimization.  Consistent      | Galeshchuk  and  Mukherjee  [34] to      |\n",
      "|                  | with their eval-  uation data, for MAPE  | evolve a special set of proï¬table        |\n",
      "|                  | evaluation  ELM DE provides  rock bottom | trading  rules inspired   from a         |\n",
      "|                  | error.  For MAE, ARV, and Theils U       | weighted  moving  average  method.  For  |\n",
      "|                  | models ELM TLBO, ELM PSO and ELM Jaya    | generating  rules, their  Genetic        |\n",
      "|                  | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 1\u001b[0m                        | algorithm  signiï¬cantly  returns above   |\n",
      "|                  | dictive models that were based on        | the exhausted  search. An-               |\n",
      "|                  | trading  rules. Trading  rules deï¬ne  a  | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 14\u001b[0m our                   |\n",
      "|                  | traderâ€™s  entry, exit, and money         | proposed  hybrid model against  a simple |\n",
      "|                  | management  criteria.  These rules are   | statistical  model that uses  the simple |\n",
      "|                  | necessary  for calling a trade           | moving  average  of the previous         |\n",
      "|                  | successful  or poor. Such a rule-based   | 20-days  closing price. Al-  though,     |\n",
      "|                  | model  was proposed  by Jia, Yang, Xiao, | this model produces  less error for      |\n",
      "|                  | Changqin,  Gansen,  and Yong [23] for    | EUR/USD  and USD/CHF  in  30-mins        |\n",
      "|                  | FOREX online prediction  that used the   | timeframe,  but it has a very high risk  |\n",
      "|                  | weighted  majority  (WM) algo-  rithm    | associated  with it. In  terms of risk   |\n",
      "|                  | for selecting  experts.  It was          | associated  with the return, the         |\n",
      "|                  | challenging  for them to maintain  a     | proposed  model maintains   its          |\n",
      "|                  | good prediction  rate when the system    | superiority  among all the models for    |\n",
      "|                  | does continuous  prediction.  So,        | both timeframes.  Although  the          |\n",
      "|                  | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 8\u001b[0m the                    | proposed  model has a good predictive    |\n",
      "|                  | future predictions  for 10 minutes  and  | capability,  it sometimes  suï¬€ers        |\n",
      "|                  | 30 minutes  are done and the  systemâ€™s   | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 8\u001b[0m the                    |\n",
      "|                  | performance  is measured.   4.4. Model   | future predictions  for 10 minutes  and  |\n",
      "|                  | validation   Validation  is an important | 30 minutes  are done and the  systemâ€™s   |\n",
      "|                  | step that is used to check the           | performance  is measured.   4.4. Model   |\n",
      "|                  | performance   of the system by comparing | validation   Validation  is an important |\n",
      "|                  | the actual data with predicted  data.    | step that is used to check the           |\n",
      "|                  | Here we have used MSE (Mean Squared      | performance   of the system by comparing |\n",
      "|                  | Error), RMSE (Root Mean Square Error),   | the actual data with predicted  data.    |\n",
      "|                  | MAE (Mean Absolute  Error), and          | Here we have used MSE (Mean Squared      |\n",
      "|                  | R-squared  ( ð‘… 2 ) value for measuring   | Error), RMSE (Root Mean Square Error),   |\n",
      "|                  | the  performance  of our system.  Among  | MAE (Mean Absolute  Error), and          |\n",
      "|                  | them in MSE and RMSE, the error          | R-squared  ( ð‘… 2 ) value for measuring   |\n",
      "|                  | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 14\u001b[0m our                   | the  performance  of our system.  Among  |\n",
      "|                  | proposed  hybrid model against  a simple | them in MSE and RMSE, the error          |\n",
      "|                  | statistical  model that uses  the simple | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 1\u001b[0m sion                   |\n",
      "|                  | moving  average  of the previous         | (MLR), CRT regression  tree, and partial |\n",
      "|                  | 20-days  closing price. Al-  though,     | least squares  (PLS) regres-  sion       |\n",
      "|                  | this model produces  less error for      | methods  were used to train their        |\n",
      "|                  | EUR/USD  and USD/CHF  in  30-mins        | dataset.  The weights  that were         |\n",
      "|                  | timeframe,  but it has a very high risk  | generated  by these four algorithms      |\n",
      "|                  | associated  with it. In  terms of risk   | were used as the inputs of the Cuckoo    |\n",
      "|                  | associated  with the return, the         | search algorithm.  The experiment  was   |\n",
      "|                  | proposed  model maintains   its          | done with two years of histori-   cal    |\n",
      "|                  | superiority  among all the models for    | data. Multiple  linear regression  (MLR) |\n",
      "|                  | both timeframes.  Although  the          | provided  better results than  SVR, PLS, |\n",
      "|                  | proposed  model has a good predictive    | and CRT. Their model outperformed  other |\n",
      "|                  | capability,  it sometimes  suï¬€ers        | regression  algo-  rithms [18] [19] .    |\n",
      "|                  | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 15\u001b[0m and                   | Another  hybrid model was developed  by  |\n",
      "|                  | nonparametric  self-organising           | Paponpat,                                |\n",
      "|                  | modelling  approach,  Expert Syst. Appl. |                                          |\n",
      "|                  | 36 (10)  (2009) 12001â€“12011,  doi:       |                                          |\n",
      "|                  | 10.1016/j.eswa.2009.03.057  .  [4] R.D.  |                                          |\n",
      "|                  | Huang, R.W. Masulis, Fx spreads and      |                                          |\n",
      "|                  | dealer competition  across the 24-hour   |                                          |\n",
      "|                  | trading day, Rev. Financ. Stud. 12 (1)   |                                          |\n",
      "|                  | (1999) 61â€“93, doi: 10.1093/rfs/12.1.61   |                                          |\n",
      "|                  | .  [5] S. Masry, A. Dupuis, R. Olsen, E. |                                          |\n",
      "|                  | Tsang, Time zone normalization  of fx    |                                          |\n",
      "|                  | seasonality,   Quant. Finance 13 (7)     |                                          |\n",
      "|                  | (2013) 1115â€“1123,  doi:                  |                                          |\n",
      "|                  | 10.1080/14697688.2013.773458  .          |                                          |\n",
      "|                  | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 9\u001b[0m                        |                                          |\n",
      "|                  | 5.1.1. EUR/USD   For the EUR/USD         |                                          |\n",
      "|                  | currency  pair, we validated  the model  |                                          |\n",
      "|                  | against   14886 samples  for our 10-mins |                                          |\n",
      "|                  | model and 3723 samples  for our 30-mins  |                                          |\n",
      "|                  | model that is 20% of our total data      |                                          |\n",
      "|                  | respectively.  The model is trained      |                                          |\n",
      "|                  | using the rest of the data. Figs. 3 and  |                                          |\n",
      "|                  | 4 present  the distribution  of dif-     |                                          |\n",
      "|                  | ferences  between  actual and predicted  |                                          |\n",
      "|                  | curve provided  in Figs. 5 and  6 ,      |                                          |\n",
      "|                  | respectively.  The x -axis represents    |                                          |\n",
      "|                  | the diï¬€erence  between  the actual       |                                          |\n",
      "|                  | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 10\u001b[0m                       |                                          |\n",
      "|                  | model, these values are 0.00084,         |                                          |\n",
      "|                  | 0.02895,  0.01448  and 0.93690  respec-  |                                          |\n",
      "|                  | tively. The actual vs predicted  value   |                                          |\n",
      "|                  | curves are provided  in Figs. 7 and  8 . |                                          |\n",
      "|                  | The x-axis indicates  the number  of     |                                          |\n",
      "|                  | test samples  (14871  for 10-mins        |                                          |\n",
      "|                  | model and 37224 samples  for 30-mins     |                                          |\n",
      "|                  | model) that have been used for           |                                          |\n",
      "|                  | prediction.  The actual closing values   |                                          |\n",
      "|                  | of the currency  pairs are marked   by   |                                          |\n",
      "|                  | yellow color and model predicted         |                                          |\n",
      "|                  | closing values are marked  by blue       |                                          |\n",
      "|                  | \u001b[31mfile1.pdf\u001b[0m \u001b[31mpage: 7\u001b[0m                        |                                          |\n",
      "|                  | system architecture  of our proposed     |                                          |\n",
      "|                  | system.   4.1. Data collection   The     |                                          |\n",
      "|                  | dataset was collected  from Histdata     |                                          |\n",
      "|                  | [65] website.  Data was col-  lected for |                                          |\n",
      "|                  | four major currency  pairs: EUR/USD      |                                          |\n",
      "|                  | [66] , GBP/USD  [67] ,  USD/CAD  [68] ,  |                                          |\n",
      "|                  | and USD/CHF  [69] . We have collected    |                                          |\n",
      "|                  | two years of his-  torical time series   |                                          |\n",
      "|                  | data from 1st January,  2017 to 31st     |                                          |\n",
      "|                  | December,  2018  for our 10 minutes      |                                          |\n",
      "|                  | prediction  model and from 1st January,  |                                          |\n",
      "|                  | 2019 to 30th                             |                                          |\n",
      "+------------------+------------------------------------------+------------------------------------------+\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Wraptext function for prettytable\n",
    "def wrap_text(text, width=40):\n",
    "    return \"\\n\".join(textwrap.wrap(text, width=width))\n",
    "\n",
    "# Create a table with predefined row names\n",
    "row_names = [\"combined_results\", \"condensed_result\", \"combined_sources\"]\n",
    "\n",
    "# After processing all files, create and print the tables\n",
    "for file_name, queries_results in output_table.items():\n",
    "    # Create a table with 'Type' as the leftmost column\n",
    "    table_data = [[\"Type\"] + queries]\n",
    "    \n",
    "    # Add rows to the table\n",
    "    for result_type in row_names:\n",
    "        row = [result_type.capitalize()]\n",
    "        for query in queries:\n",
    "            if result_type == \"combined_sources\":\n",
    "                sources_str = \"\\n\".join([f\"\\n{colored(k[0], 'red')} {colored(k[1], 'red')}\\n{v}\" for k, v in queries_results[query][result_type].items()])\n",
    "                row.append(wrap_text(sources_str))\n",
    "            else:\n",
    "                row.append(wrap_text(queries_results[query][result_type]))\n",
    "        table_data.append(row)\n",
    "\n",
    "    # Print the table for the current file_name with a separator between rows\n",
    "    print(f\"File: {file_name}\\n{tabulate(table_data, headers='firstrow', tablefmt='grid')}\\n{'=' * 80}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ```qa_all_at_once_iterated```\n",
    "Searches for the answer through all documents. Can also take the chat history into consideration. Does iterated prompts to get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_all_at_once(folder_path, chain_type, chunk_size, query, k, own_knowledge = False, show_pages=False):\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Read-in and split the documents\n",
    "    \"\"\"\n",
    "    all_pages = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        if file_name.endswith('.pdf'):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif file_name.endswith('.csv'):\n",
    "            loader = CSVLoader(file_path)\n",
    "        elif file_name.endswith('.docx'):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        elif file_name.endswith('.md'):\n",
    "            loader = UnstructuredMarkdownLoader(file_path)\n",
    "        else:\n",
    "            continue  # Skip files with other extensions\n",
    "\n",
    "        file = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_size/2)\n",
    "        pages = text_splitter.split_documents(file)\n",
    "        all_pages.extend(pages)\n",
    "\n",
    "    if show_pages:\n",
    "        print(len(all_pages))\n",
    "        for page in all_pages:\n",
    "            print(page)\n",
    "\n",
    "    \"\"\"\n",
    "    Vectorstores\n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    db = FAISS.from_documents(all_pages, embeddings)\n",
    "    # FAISS vectorstores can also be merged and saved to disk\n",
    "\n",
    "    \"\"\"\n",
    "    Retriever\n",
    "    \"\"\"\n",
    "    # Amount of returned documents k\n",
    "    retriever = db.as_retriever(\n",
    "        search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "\n",
    "    \"\"\"\n",
    "    Chains\n",
    "    \"\"\"\n",
    "\n",
    "    # Define Chain\n",
    "    if own_knowledge:\n",
    "        prompt_template = \"\"\"Use the following pieces of chat history and context to answer the question at the end. \\\n",
    "            If the answer does not become clear from the context, you can also use your own knowledge. \\\n",
    "            If you use your own knowledge, please indicate this clearly in your answer. \\\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        {question}\n",
    "        Helpful answer:\"\"\"\n",
    "\n",
    "    if not own_knowledge:\n",
    "\n",
    "        prompt_template = \"\"\"Use the following pieces of chat history and context to answer the question at the end. \\\n",
    "            Do NOT use your own knowledge and give the best possible answer from the context.\\\n",
    "        \n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        {question}\n",
    "        Helpful answer:\"\"\"\n",
    "\n",
    "\n",
    "    PROMPT = PromptTemplate(\n",
    "        template=prompt_template, input_variables=[\"context\",\"question\"]\n",
    "    )\n",
    "\n",
    "    chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "    # Define Chain\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=OpenAI(temperature=0),\n",
    "        chain_type=chain_type,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs=chain_type_kwargs\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Run Chain with parameters\n",
    "    result = qa(query)\n",
    "\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the chat history: \n",
      " {} \n",
      "And this is the current question: \n",
      " What is a LSTM model?.\n"
     ]
    }
   ],
   "source": [
    "# Define the Query\n",
    "query = \"What is a LSTM model?\"\n",
    "\n",
    "# Update the query with the Chat History\n",
    "query_with_context = f\"This is the chat history: \\n {str(chat_history)} \\nAnd this is the current question: \\n {query}.\"\n",
    "print(query_with_context)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Results\n",
    "In case you do not want the chat history to be part of the prompt, change ```query=query```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------\n",
      "\u001b[32mAnswer:\u001b[0m\n",
      "--------------------------------------------------------------------\n",
      "\n",
      " A Long Short-Term Memory (LSTM) model is a type of Recurrent Neural Network\n",
      "(RNN) that is capable of learning long-term dependencies. It is composed of four\n",
      "layers: an input layer, a memory unit, a cell state, and an output layer. The\n",
      "key component of the LSTM is the cell state, which runs straight down the entire\n",
      "timesteps with only minor but important interactions. LSTM can add or remove\n",
      "information from the cell state using several gates, each of which is made of a\n",
      "sigmoid neural network layer. These sigmoid layers produce output numbers\n",
      "between 0 and 1, which represent how much information is kept or removed from\n",
      "the cell state. LSTM models can be trained using an optimization algorithm like\n",
      "gradient descent on a set of training sequences.\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\u001b[32mSources:\u001b[0m\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "('file1.pdf', 'page: 5')\n",
      "('file2.pdf', 'page: 5')\n",
      "('file1.pdf', 'page: 5')\n",
      "('file2.pdf', 'page: 5')\n"
     ]
    }
   ],
   "source": [
    "# Get Results\n",
    "result = qa_all_at_once(folder_path=folder_path, \n",
    "            chain_type=\"stuff\",\n",
    "            chunk_size=1000, \n",
    "            query=query_with_context, \n",
    "            k=4, \n",
    "            own_knowledge = True, \n",
    "            show_pages=False)\n",
    "\n",
    "# Append Queries and Answers to Chat History\n",
    "chat_history[query] = result['result']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Define Sources\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m sources \u001b[39m=\u001b[39m [(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(doc\u001b[39m.\u001b[39mmetadata[\u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m]), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpage: \u001b[39m\u001b[39m{\u001b[39;00mdoc\u001b[39m.\u001b[39mmetadata[\u001b[39m'\u001b[39m\u001b[39mpage\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m result[\u001b[39m'\u001b[39m\u001b[39msource_documents\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m      4\u001b[0m \u001b[39m# Sort sources by filename and page number\u001b[39;00m\n\u001b[0;32m      5\u001b[0m sorted_sources \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(sources, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: (x[\u001b[39m0\u001b[39m], \u001b[39mint\u001b[39m(x[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m])))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "# Define Sources\n",
    "sources = [(os.path.basename(doc.metadata[\"source\"]), f\"page: {doc.metadata['page']}\") for doc in result['source_documents']]\n",
    "\n",
    "# Sort sources by filename and page number\n",
    "sorted_sources = sorted(sources, key=lambda x: (x[0], int(x[1].split(\" \")[1])))\n",
    "\n",
    "# Print Answer and Sources\n",
    "print(\"\\n--------------------------------------------------------------------\")\n",
    "print(colored(\"Answer:\", \"green\"))\n",
    "print(\"--------------------------------------------------------------------\\n\")\n",
    "print(textwrap.fill(result['result'], width=80))\n",
    "print(\"\\n--------------------------------------------------------------------\")\n",
    "print(colored(\"Sources:\", \"green\"))\n",
    "print(\"--------------------------------------------------------------------\\n\")\n",
    "for source in sorted_sources:\n",
    "    print(source)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ```qa_all_at_once_iterated```\n",
    "Searches for the answer through all documents. Can also take the chat history into consideration. Does iterated prompts to get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_all_at_once_iterated(folder_path, chain_type, query, k, num_iterations, max_tokens,own_knowledge = False, show_pages=False):\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Prompts\n",
    "    \"\"\"\n",
    "\n",
    "    # Define Chain\n",
    "    if own_knowledge:\n",
    "        prompt_template = \"\"\"Use the following pieces of chat history and context to answer the question at the end. \\\n",
    "            If the answer does not become clear from the context, you can also use your own knowledge. \\\n",
    "            If you use your own knowledge, please indicate this clearly in your answer. \\\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        {question}\n",
    "        Helpful answer:\"\"\"\n",
    "\n",
    "    if not own_knowledge:\n",
    "\n",
    "        prompt_template = \"\"\"Use the following pieces of chat history and context to answer the question at the end. \\\n",
    "            Do NOT use your own knowledge and give the best possible answer from the context.\\\n",
    "        \n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        {question}\n",
    "        Helpful answer:\"\"\"\n",
    "\n",
    "\n",
    "    PROMPT = PromptTemplate(\n",
    "        template=prompt_template, input_variables=[\"context\",\"question\"]\n",
    "    )\n",
    "\n",
    "    chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Chains\n",
    "    \"\"\"\n",
    "    # Define summary chain\n",
    "    text_splitter = CharacterTextSplitter()\n",
    "    qa_condense = load_summarize_chain(llm=OpenAI(temperature=0), chain_type=\"stuff\")\n",
    "    \n",
    "    extended_answers = []\n",
    "    unique_sources = set()\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        # Define the chunk size\n",
    "        num_chunks = k-i\n",
    "\n",
    "        # Amount of tokens that GPT-3.5 can handle. This can be upped later on.\n",
    "        chunk_size = int(max_tokens/num_chunks)-1\n",
    "\n",
    "        \"\"\"\n",
    "        Read-in and split the documents\n",
    "        \"\"\"\n",
    "        all_pages = []\n",
    "\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            if file_name.endswith('.pdf'):\n",
    "                loader = PyPDFLoader(file_path)\n",
    "            elif file_name.endswith('.csv'):\n",
    "                loader = CSVLoader(file_path)\n",
    "            elif file_name.endswith('.docx'):\n",
    "                loader = Docx2txtLoader(file_path)\n",
    "            elif file_name.endswith('.md'):\n",
    "                loader = UnstructuredMarkdownLoader(file_path)\n",
    "            else:\n",
    "                continue  # Skip files with other extensions\n",
    "\n",
    "            file = loader.load()\n",
    "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_size/2)\n",
    "            pages = text_splitter.split_documents(file)\n",
    "            all_pages.extend(pages)\n",
    "\n",
    "        if show_pages:\n",
    "            print(len(all_pages))\n",
    "            for page in all_pages:\n",
    "                print(page)\n",
    "\n",
    "        \"\"\"\n",
    "        Vectorstores\n",
    "        \"\"\"\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "\n",
    "        db = FAISS.from_documents(all_pages, embeddings)\n",
    "        # FAISS vectorstores can also be merged and saved to disk\n",
    "\n",
    "        \"\"\"\n",
    "        Chains\n",
    "        \"\"\"\n",
    "\n",
    "        # QA chain that is adaptable\n",
    "        # Amount of returned documents k-i -> makes it adaptable. Otherwise, it would always return k documents and the output would be the same.\n",
    "        retriever = db.as_retriever(\n",
    "            search_type=\"similarity\", search_kwargs={\"k\": num_chunks})\n",
    "\n",
    "        # Define retrieval chain\n",
    "        qa = RetrievalQA.from_chain_type(\n",
    "            llm=OpenAI(temperature=0),\n",
    "            chain_type=chain_type,\n",
    "            retriever=retriever,\n",
    "            return_source_documents=True,\n",
    "            chain_type_kwargs=chain_type_kwargs\n",
    "        )\n",
    "\n",
    "        # Run Chain with parameters\n",
    "        result = qa(query)\n",
    "\n",
    "        # Get Sources\n",
    "        sources = [(doc.page_content, os.path.basename(doc.metadata[\"source\"]), f\"page: {doc.metadata['page']}\") for doc in\n",
    "                result['source_documents']]\n",
    "\n",
    "        # Append result to extended_answers\n",
    "        extended_answers.append(result['result'])\n",
    "\n",
    "        # Add sources to the unique_sources set\n",
    "        unique_sources.update(sources)\n",
    "\n",
    "    \"\"\"\n",
    "    Final dfs\n",
    "    \"\"\"\n",
    "\n",
    "    # Combine extended_answers\n",
    "    combined_result = ' '.join(extended_answers)\n",
    "\n",
    "    # Run the qa function on the combined_result (summary)\n",
    "    texts = text_splitter.split_text(combined_result)\n",
    "    docs = [Document(page_content=t) for t in texts[:3]]\n",
    "    \n",
    "    condensed_result = str(qa_condense.run(docs))\n",
    "\n",
    "    # Combine unique_sources\n",
    "    combined_sources = {tuple([source[1], source[2]]): source[0] for source in unique_sources}\n",
    "\n",
    "    \n",
    "    return combined_result, condensed_result, combined_sources"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the chat history: \n",
      " {} \n",
      "And this is the current question: \n",
      " What is a LSTM model?.\n"
     ]
    }
   ],
   "source": [
    "# Define the Query\n",
    "query = \"What is a LSTM model?\"\n",
    "\n",
    "# Update the query with the Chat History\n",
    "query_with_context = f\"This is the chat history: \\n {str(chat_history)} \\nAnd this is the current question: \\n {query}.\"\n",
    "print(query_with_context)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Results\n",
    "In case you do not want the chat history to be part of the prompt, change ```query=query```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Results\n",
    "combined_result, condensed_result, combined_sources = qa_all_at_once_iterated(folder_path=folder_path, \n",
    "            chain_type=\"stuff\",\n",
    "            query=query_with_context, \n",
    "            k=8, \n",
    "            num_iterations=4,\n",
    "            max_tokens=4000,\n",
    "            own_knowledge = True, \n",
    "            show_pages=False)\n",
    "\n",
    "# Append Queries and Answers to Chat History\n",
    "chat_history[query] = condensed_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------\n",
      "\u001b[32mCombined Answer:\u001b[0m\n",
      "--------------------------------------------------------------------\n",
      "\n",
      " A LSTM (Long Short Term Memory) model is a variation of a recurrent neural\n",
      "network which can be trained using an optimization algorithm like gradient\n",
      "descent on a set of training sequences. It was first introduced by Hochreiter\n",
      "and Schmidhuber in 1997 as an updated version of RNN for addressing the problems\n",
      "like vanishing gradient and later was simplified or refined. LSTM is capable of\n",
      "learning long term dependencies and is capable of remembering for a long period\n",
      "of time using a memory unit.  A Long Short Term Memory (LSTM) model is a\n",
      "variation of a recurrent neural network which can be trained using an\n",
      "optimization algorithm like gradient descent on a set of training sequences. It\n",
      "was first introduced by Hochreiter and Schmidhuber in 1997 as an updated version\n",
      "of RNN for addressing the problems like vanishing gradient and later were\n",
      "simplified or refined. LSTM is combined with backpropagation through time and is\n",
      "used for time series prediction because of its capability to remember each and\n",
      "every information through time and also for improved prediction ability using\n",
      "the previous inputs of the system. It is more accurate than GRU, but requires\n",
      "more time and memory.  A Long Short Term Memory (LSTM) model is a type of\n",
      "recurrent neural network (RNN) that is capable of learning long term\n",
      "dependencies. It is composed of four layers: a sigmoid neural network layer, a\n",
      "memory unit, a cell state, and a layer of tanh. The sigmoid layer produces\n",
      "output numbers between 0 and 1, which represent how much information should be\n",
      "let through. The memory unit allows the LSTM to remember for a long period of\n",
      "time. The cell state runs straight down the entire timesteps with only minor but\n",
      "important interactions. Finally, the tanh layer is used to change all the\n",
      "weights of the LSTM network in proportion to the derivation of the error rate\n",
      "concerning the corresponding weight.  A Long Short Term Memory (LSTM) model is a\n",
      "variation of a Recurrent Neural Network (RNN) which can be trained using an\n",
      "optimization algorithm like gradient descent on a set of training sequences. It\n",
      "was first introduced by Hochreiter and Schmidhuber in 1997 as an updated version\n",
      "of RNN for addressing the problems like vanishing gradient and later were\n",
      "simplified or refined. LSTM is combined with backpropagation through time and is\n",
      "used for time series prediction because of its capability to remember each and\n",
      "every information through time and also for improved prediction ability using\n",
      "the previous inputs of the system.\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\u001b[32mCondensed Answer:\u001b[0m\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "  A Long Short Term Memory (LSTM) model is a type of recurrent neural network\n",
      "(RNN) that is capable of learning long term dependencies. It was first\n",
      "introduced by Hochreiter and Schmidhuber in 1997 as an updated version of RNN\n",
      "for addressing the problems like vanishing gradient and later were simplified or\n",
      "refined. It is composed of four layers: a sigmoid neural network layer, a memory\n",
      "unit, a cell state, and a layer of tanh. LSTM is used for time series prediction\n",
      "because of its capability to remember each and every information through time\n",
      "and also for improved prediction ability using the previous inputs of the\n",
      "system.\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\u001b[32mCombined Sources:\u001b[0m\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\u001b[31mSource: file1.pdf page: 0\u001b[0m\n",
      " nature of this unsettled  market. This paper presents  a new model\n",
      "that combines  two powerful  neural networks   used for time series\n",
      "prediction:  Gated Recurrent  Unit (GRU) and Long Short Term Memory\n",
      "(LSTM),  for predicting   the future closing prices of FOREX\n",
      "currencies.  The ï¬rst layer of our proposed  model is the GRU layer\n",
      "with 20  hidden neurons  and the second layer is the LSTM layer with\n",
      "256 hidden neurons.  We have applied our model on\n",
      "\n",
      "\n",
      "\u001b[31mSource: file1.pdf page: 1\u001b[0m\n",
      " of RNN (Recurrent  Neural Network)  for time series prediction\n",
      "because   of its capability  to remember  each and every information\n",
      "through  time  and also for improved  prediction  ability using the\n",
      "previous  inputs of the  system.  LSTM has proven to be the most\n",
      "accurate  and successful  algo-  rithm in time series prediction\n",
      "closely following  by GRU [16] . GRU is  a revised  version  of LSTM\n",
      "but the working  procedure  is quite similar.   GRU requires  less\n",
      "memory  as it uses less training  parameters  thus its  faster than\n",
      "LSTM. Though  LSTM is a bit of time-consuming,  it is more  accurate\n",
      "as it uses longer sequences.  This motivated  us to build a hy-  brid\n",
      "model based on two of the most promising  neural networks  and to\n",
      "\n",
      "\n",
      "\u001b[31mSource: file1.pdf page: 4\u001b[0m\n",
      " M.S. Islam and E. Hossain Soft Computing  Letters 3 (2021) 100009\n",
      "Fig. 4. Distribution  of diï¬€erences  between  ac-  tual and predicted\n",
      "curve for EUR/USD  30-mins   timeframe.   proved result for open and\n",
      "low. But for longer-term  prediction  (whole  month)  the result\n",
      "changed  where GA-NN provided  a higher result for  open and high and\n",
      "for the remainder  ASTAR was better result provider   while SVM always\n",
      "provided  a mean value of GA-NN and ASTAR.  Many  other systems\n",
      "supported  neural network  was implemented  in these pre-  vious years\n",
      "as well [60,61]  .  3. An overview  of GRU and LSTM\n",
      "\n",
      "\n",
      "\u001b[31mSource: file1.pdf page: 5\u001b[0m\n",
      " current  content  will be ignored  since it is irrelevant  for the\n",
      "prediction.   At the same time, since zt will be close to 0 at this\n",
      "time step, 1-zt  will be close to 1, allowing  the majority  of the\n",
      "past information  to be  kept.  3.2. Long short term memory   An LSTM\n",
      "is another  variation  of recurrent  neural network  which can  be\n",
      "trained  using an optimization  algorithm  like gradient  descent  on\n",
      "a set  of the training  sequence.  LSTM was ï¬rst introduced  by\n",
      "Hochreiter  and  Schmidhuber  [63] in 1997 as an updated  version  of\n",
      "RNN for addressing   the problems  like vanishing  gradient  and later\n",
      "were simpliï¬ed  or re-\n",
      "\n",
      "\n",
      "\u001b[31mSource: file1.pdf page: 7\u001b[0m\n",
      " tains LSTM with 256 hidden neurons.  The third layer and fourth\n",
      "layers  are dense layers with 64 and 1 hidden neurons  respectively.\n",
      "We have  trained  this model using the 10 minutes  and 30 minutes\n",
      "interval  data  which we have processed  from the original  1-minute\n",
      "interval  data. The\n",
      "\n",
      "\n",
      "\u001b[31mSource: file1.pdf page: 9\u001b[0m\n",
      " [16] in time series prediction.  Both of the GRU and LSTM model were\n",
      "trained  using the same data- sets, same hidden layer formation  and\n",
      "was  run 100 times each as our proposed  model. Moreover,  this\n",
      "proposed   model is also compared  against  a simple statistical\n",
      "model that uses the  moving  average  of the previous  20 days closing\n",
      "price to predict future prices. The following  4 subsections  discuss\n",
      "the results of four major cur-  rency pairs we have used in this\n",
      "research.\n",
      "\n",
      "\n",
      "\u001b[31mSource: file1.pdf page: 11\u001b[0m\n",
      " GRU-LSTM  model against  a standalone  GRU model, a standalone  LSTM\n",
      "model, and a simple statistical  model where we have used simple mov-\n",
      "ing average  (SMA) of previous  20-days  closing price. Moving\n",
      "average  is  used for ï¬ltering  out the noise and smoothing  the price\n",
      "trend. We have  considered  a 20-days  moving  average  for analyzing\n",
      "the performance  as  a 20-days  moving  average  is proven to provide\n",
      "the best result [70] .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print Answer and Sources\n",
    "print(\"\\n--------------------------------------------------------------------\")\n",
    "print(colored(\"Combined Answer:\", \"green\"))\n",
    "print(\"--------------------------------------------------------------------\\n\")\n",
    "print(textwrap.fill(combined_result, width=80))\n",
    "print(\"\\n--------------------------------------------------------------------\")\n",
    "print(colored(\"Condensed Answer:\", \"green\"))\n",
    "print(\"--------------------------------------------------------------------\\n\")\n",
    "print(textwrap.fill(condensed_result, width=80))\n",
    "print(\"\\n--------------------------------------------------------------------\")\n",
    "print(colored(\"Combined Sources:\", \"green\"))\n",
    "print(\"--------------------------------------------------------------------\\n\")\n",
    "\n",
    "# Print Sources and Sort them first\n",
    "for source_key, source_element in sorted(combined_sources.items(), key=lambda x: (x[0][0], int(x[0][1].split(\" \")[1]))):\n",
    "    print(colored(f\"Source: {source_key[0]} {source_key[1]}\", \"red\"))\n",
    "    print(textwrap.fill(f'\\n{source_element}\\n'))\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
